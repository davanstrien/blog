{
  
    
        "post0": {
            "title": "Power, Ethics and AI for GLAMs",
            "content": "This is a very quick rambling post on ethics/power and ai in a GLAM setting. . On a recent(ish) call for the fastai4fglams study group we discussed Lecture 5 of the fast.ai course which focuses on Ethics. . A question we discussed in the call was about the more specific ethical issues that could emerge when using AI in a library context. . Some of the topics we touched on in the discussion included: . The Provenance of collection items | How this provenance is represented (or not) in metadata | The use of Black Box commercial solutions for working with GLAM data | The alternatives (or lack of) to using machine learning for some tasks | How much to document the provenance of a label produced by ml | . How to present labels produced via machine learning . I should preface this discussion by saying I am not an expert in cataloging or the associated literature. . Instead of trying to cover all of these issues I will focus on one particular question for GLAMs using machine learning: how to display the labels produced by these models in library systems i.e. catalogues? . One of the main uses cases of Machine Learning models is to produce labels for collections items. These labels could either seek to ‚Äòaugment‚Äô or ‚Äòreplace‚Äô existing metadata records fields. A question for either of these is how to display, store and manage labels produced via machine learning models in library systems. For example a model which is trained to predict the year field for items in a particular collection. . The model . Knowing the model which produced a label including: . the architecture | the year in which the model was trained/inference made | version of the model | ‚Ä¶ | . There is a danger of replicated the granularity of tools like Weights and Biases. Whilst this information is useful for training and provenance for people familiar with machine learning methods, some of the information in these systems is going to be less relevant for a typical library catalog user e.g. GPU memory consumption during training. There are potentially some other fields which will be more relevant to a broader number of people. . Possible labels . The first question for this type of task might be to know how the original model task was defined. Predicting labels for ‚Äòyear‚Äô could be treated as a classification task. For example if you have a collection where you a certain that all items in that collection will have been produced between certain dates the task may be to predict classify whether the item belong to the 80s or 50s decade. In this case the model has a restricted range of possible outputs i.e. each decade in the original training data. . Another approach would be to instead make this a ‚Äòregression‚Äô task, where the model predicts a continuous value. In this case the model is not bound by a particular set of possible years. . The distinction between a classification and a regression model, and the possible bound of values for a label might give the end-user of that label a better sense of how it should be ‚Äòread‚Äô. Using this information will also provide some way of contextualizing the confidence of the label, and what this might mean. An F1 score will mean different things if a model had to choose between one five possible decades for a year label or choose one of a 100 possible years. . Alongside knowing the potential labels, it may be useful for a user of a catalog to know something about the distribution of these labels i.e. how many times does a certain label appear both during the inference and training steps. . Training data . Having at least a minimal way of interrogating the original training data could allow for more interrogation of models even by those who aren‚Äôt experts in machine learning and in fact domain experts might pick up on important features of a training dataset that might have been missed during it‚Äôs construction. Including some information about: . number of training examples | label distribution | min, max values | etc. | . Ideally this dataset would be available for open use by others but this might not always be possible for collections which aren‚Äôt fully open. . How to present this information? . To be continued‚Ä¶ .",
            "url": "https://danielvanstrien.xyz/fastai%20course/ethics/2020/11/05/power-ethics-and-ai-in-glams.html",
            "relUrl": "/fastai%20course/ethics/2020/11/05/power-ethics-and-ai-in-glams.html",
            "date": " ‚Ä¢ Nov 5, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Image labeling vs classification models",
            "content": "The &#39;hello world&#39; example for introducing deep learning based computer vision often involves classifying images as üê∂ or üê±. An alternative approach to classifying images is to instead apply labels. This is usually introduced in the context of multi-label classification i.e. where an image can have more than one label. In this blog post I discuss some of the differences between these two approaches, specifically the difference in loss functions, and how these two approaches might work better depending on the application. The post starts with a conceptual overview of the differences between these two approaches, before showing the different loss functions and then moving to a practical example of training these two different types of model. . Image Classification vs Image Labeling . In a classification model, an input can have only one label. This could be one of a few or one of a hundred, regardless of the number of potential classes, it is assumed that the input only belongs to one of these. With a model that applies labels this is not true an input can have one, multiple or no labels. . Sorting through family photos . We can use an analogy to illustrate the difference between these two approaches. Let&#39;s say you were sorting through some old family photographs. You might &quot;classify&quot; the photos into one (and only one) of two photo albums, depending on whether they are black-and-white or colour. This would be comparable to using a classification model since each photo will go into exactly one of these two albums - a photo cannot be both simultaneously colour and black-and-white, and it cannot be neither colour nor black-and-white. . You may at the same time also want to make it easier to find photos of particular people in your family. You could do this by assigning labels to each photo, indicating or &quot;tagging&quot; the family members who appear in the photo. In this case, a photo may have one label (a photo of your sister), more than one label (a photo of your sister and aunt), or it may have no labels (a photograph of a landscape taken on a holiday). This would be analogous to a multi-label classification model. . The choice between using a model which performs classification or a model which assigns labels should be considered in relation to the role your model has. It is also useful to look a little bit more closely as how these different types of models work under the hood. . CrossEntropyLoss vs BCEWithLogitsLoss . When we create a model which does classifications or applies labels, the distinction, if using the same data is that they use different loss functions. . A classification model will use a variant of Cross Entropy Loss whilst the label model will use a BCE with Logits Loss. We&#39;ll see how this is inferred by fastai below but fore now take my word for it... . Let&#39;s take a look at a snippet of the Pytorch docs for each of these loss functions . CrossEntropyLoss . This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class. It is useful when training a classification problem with C classes. If provided, the optional argument weight should be a 1D Tensor assigning weight to each of the classes. This is particularly useful when you have an unbalanced training set. Read more . BCEWithLogitsLoss . This loss combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable than using a plain Sigmoid followed by a BCELoss as, by combining the operations into one layer, we take advantage of the log-sum-exp trick for numerical stability. Read more . Let&#39;s see what these do to some activations. First we&#39;ll import required packages . import torch.nn as nn import numpy as np import torch . Exploring CrossEntropyLoss . We can create some fake activations. To start we&#39;ll just consider one output with three classes. We&#39;ll start with one to keep things simple for now. . one_act = torch.randn((1, 3)) * 1 one_act . tensor([[ 0.9924, 0.8698, -0.0100]]) . We can think of these activations as probabilities for one of three classes. Let&#39;s see what these sum to. . one_act.sum() . tensor(1.0875) . We can see that these activations don&#39;t sum to 1. If we want our image input to belong to only one class, then the labels are not mutually exclusive of each other i.e. if one label probability is higher, another needs to be lower i.e. the probabilities need to add up to 1. Going back to the Pytorch explanation of CrossEntropyLoss we see that one component is nn.LogSoftmax(). What is particularly relevant here is that &#39;softmax&#39; part. Let&#39;s see what this does to our activation . softmax_acts = torch.softmax(one_act, dim=1) softmax_acts . tensor([[0.4525, 0.0381, 0.5093]]) . You can probably already see how this has changed the nature of these activations. Let&#39;s call sum on these outputs again. . softmax_acts.sum() . tensor(1.) . We now have a sum of 1! We can now treat this as the probability of an input image belonging to a particular class. We could then call argmax to find out which class the model is most confident about and use that as our prediction. . softmax_acts.argmax(dim=1) . tensor([2]) . One of the potential issues that was mentioned about using a classification model was that it doesn&#39;t account for ambiguities in the labels very well. . What is softmax doing? . Digging into what softmax does in a little bit more detail will show what is going on here. . First lets see what softmax actually does, I&#39;ll skip the LaTeX formula from Wikepedia because it makes is look much scarier than the Python code example: . a = [1.0, 2.0, 3.0, 4.0, 1.0, 2.0, 3.0] np.exp(a) / np.sum(np.exp(a)) . array([0.02364054, 0.06426166, 0.1746813 , 0.474833 , 0.02364054, 0.06426166, 0.1746813 ]) . This is much easier for me to parse compared to the Greek. Let&#39;s look at the different parts. Working with one set of activations again: . one_act . tensor([[ 1.1479, -1.3265, 1.2661]]) . Starting from np.exp(a) we can do this in Pytorch like: . one_act.exp() . tensor([[3.1515, 0.2654, 3.5471]]) . We can convert the rest of the numpy code as follows . one_act.exp().sum(dim=1) . tensor([6.9641]) . Putting it all together we get . (one_act.exp() /one_act.exp().sum(dim=1)).sum(dim=1) . tensor([1.]) . This seems to work as expected, i.e. we get the probabilities to sum to 1. To make it clearer what&#39;s going on though, it&#39;s useful to look a little more closely at the difference using exp makes. Let&#39;s import the standard python version of exp and check the docs. . from math import exp doc(exp) . exp[source] . exp(x) . Return e raised to the power of x. . What difference does using the exponent make? We&#39;ll use a simple array of values to keep things simple . x = np.array([1,2,4,1]) x . array([1, 2, 4, 1]) . Now if we want these to be converted to probabilities for different classes we need them to sum to 1. We could just do this by dividing each element by the sum. . x/x.sum() . array([0.125, 0.25 , 0.5 , 0.125]) . We can confirm this add to 1 . (x/x.sum()).sum() . 1.0 . Now this seems to work to get us probabilities for each class. Let&#39;s compare doing the same thing but using exp to create exponents of the inputs . np.exp(x)/np.sum(np.exp(x)) . array([0.04031637, 0.10959126, 0.80977599, 0.04031637]) . Again we get an array of probabilities, let&#39;s confirm they add to one. . one_act.exp()/one_act.exp().sum(dim=1) . tensor([[0.4441, 0.3929, 0.1630]]) . So what is different here? . Let&#39;s put the two arrays next to each other so we can compare the values for each index . np.exp(x)/ np.sum(np.exp(x)), (x/ x.sum()) . (array([0.04031637, 0.10959126, 0.80977599, 0.04031637]), array([0.125, 0.25 , 0.5 , 0.125])) . Other than the difference in decimals, you will probably notice that when we use exponent, some labels for a class have been pushed much higher. Index 2 is 0.80 when we use exp and only 0.5 when we don&#39;t use the exponent. This is an important difference here. By using the magic properties of $e$ we &#39;push&#39; one probability to be higher than the others. . This property is useful when we have a clear distinction between classes. If we were predicting handwritten digits there (should) only be one correct answer. In this case having one class prediction being pushed much higher would be a good thing. . If however, we have labels which are more ambiguous, this would be less of a desirable property. Even if we try and capture ambiguity by using the raw probabilities of the labels, rather than taking the argmax value, the numerical properties of the softmax function mean that it likely that one label value will be pushed higher than the others. . We&#39;ll look at a practical example later on to illustrate this. Let&#39;s now quickly compare our other loss function . Exploring BCEWithLogitsLoss . As a reminder . This loss combines a Sigmoid layer and the BCELoss in one single class. . The part here that we are particularly interested in is the Sigmoid. Let&#39;s use one_acts again . one_act . tensor([[ 1.1479, -1.3265, 1.2661]]) . As a reminder sigmoid function can be plotted as . You&#39;ll probably be familiar with sigmoid as one of the potential activations functions you can use in the a neural network. The property we care about is that it squishes inputs into a value between 0 and 1. Let&#39;s do this for our activations . torch.sigmoid(one_act) . tensor([[0.7591, 0.2097, 0.7801]]) . We can see that all our values have been pushed between 0 and 1. However, we can also see they don&#39;t sum to 1. . torch.sigmoid(one_act).sum() . tensor(1.7489) . What we have here is a probability for each label which is independent of the probability of the other labels. The sigmoid function makes sure the activations for each label becomes a probability but it doesn&#39;t make sure that all of the labels probabilities sum to 1. Looking at a practical example using fastai might illustrate this difference. . We&#39;ll work with some images taken from 19th Century books, the specific images in this case don&#39;t matter to do much . We&#39;ll import fastai and then put images from two folders &#39;building&#39; and &#39;coat&#39; into a Pandas DataFrame. . from fastai.vision.all import * . files = get_image_files(&#39;data/cv_workshop_exercise_data/&#39;, folders=[&#39;building&#39;, &#39;coat&#39;]) df = pd.DataFrame(files.items, columns=[&#39;fname&#39;]) df[&#39;class_label&#39;] = df[&#39;fname&#39;].apply(lambda x: x.parts[2]) df[&#39;class_label&#39;].value_counts() . building 44 coat 26 Name: class_label, dtype: int64 . We can see we have two possible classes building and coat. First we&#39;ll load these into fastai as a classification model. . dls_classification = ImageDataLoaders.from_df(df,fn_col=&#39;fname&#39;,valid_pct=0.4, label_col=&#39;class_label&#39;, item_tfms=Resize(128, ResizeMethod.Squish), bs=8,num_workers=0) . dls_classification.show_batch() . You&#39;ll see that building refers to a building, whilst a coat refers to a coat of arms. Let&#39;s now load this data into fastai . learn = cnn_learner(dls_classification, resnet18, metrics=[accuracy, F1Score()]) . Often if we pass fastai a dataloader it will be able to infer the correct loss function based on this data. we can access this using the loss_func attribute. . learn.loss_func . FlattenedLoss of CrossEntropyLoss() . As promised this is a variant on the CrossEntropyLoss we saw earlier. Let&#39;s now fit it for a bit. . learn.fit(5) . epoch train_loss valid_loss accuracy f1_score time . 0 | 1.023169 | 0.786303 | 0.785714 | 0.769231 | 00:03 | . 1 | 0.721281 | 0.576258 | 0.821429 | 0.814815 | 00:03 | . 2 | 0.477446 | 0.339626 | 0.821429 | 0.782609 | 00:04 | . 3 | 0.423173 | 0.331097 | 0.821429 | 0.782609 | 00:03 | . 4 | 0.351390 | 0.239433 | 0.857143 | 0.818182 | 00:03 | . Now we have a model, we&#39;ll grab the predictions . acts, _ = learn.get_preds() acts . tensor([[9.9795e-01, 2.0519e-03], [9.9811e-01, 1.8889e-03], [9.9911e-01, 8.8577e-04], [9.9680e-01, 3.2038e-03], [6.5879e-01, 3.4121e-01], [1.2512e-04, 9.9987e-01], [9.9734e-01, 2.6599e-03], [9.8866e-01, 1.1341e-02], [9.2739e-01, 7.2608e-02], [9.8336e-01, 1.6643e-02], [1.7059e-01, 8.2941e-01], [9.9899e-01, 1.0067e-03], [5.2081e-01, 4.7919e-01], [4.9184e-03, 9.9508e-01], [9.9930e-01, 7.0161e-04], [1.0109e-04, 9.9990e-01], [9.9533e-01, 4.6670e-03], [3.6834e-02, 9.6317e-01], [5.7022e-06, 9.9999e-01], [9.8635e-01, 1.3647e-02], [2.1610e-01, 7.8390e-01], [2.3512e-02, 9.7649e-01], [2.9994e-01, 7.0006e-01], [4.2728e-02, 9.5727e-01], [9.8494e-01, 1.5062e-02], [1.4194e-01, 8.5806e-01], [6.8620e-01, 3.1380e-01], [7.3493e-01, 2.6507e-01]]) . These are the predictions for each class, let&#39;s confirm these all sum to 1. . acts.sum(dim=1) . tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]) . If we look at the max for each probability we&#39;ll see they tend to be high. . acts.max(dim=1)[0] . tensor([0.9979, 0.9981, 0.9991, 0.9968, 0.6588, 0.9999, 0.9973, 0.9887, 0.9274, 0.9834, 0.8294, 0.9990, 0.5208, 0.9951, 0.9993, 0.9999, 0.9953, 0.9632, 1.0000, 0.9864, 0.7839, 0.9765, 0.7001, 0.9573, 0.9849, 0.8581, 0.6862, 0.7349]) . Looking at the mean, max and min: . acts.max(dim=1)[0].mean(), acts.max(dim=1)[0].max(), acts.max(dim=1)[0].min(), . (tensor(0.9113), tensor(1.0000), tensor(0.5208)) . This is desirable if the input we are trying to label does neatly fit the categories but if we are trying to label something which is more ambiguous then this might be less useful. A particular case where this certainty might not be so helpful is when your model may possibly face out of domain images, i.e. see things it hasn&#39;t seen before and for which none of the classes it is trying to predict should apply. Let&#39;s load a new dataset of images of people. . people = get_image_files(&#39;data/cv_workshop_exercise_data/&#39;, folders=&#39;people&#39;) people . (#38) [Path(&#39;data/cv_workshop_exercise_data/people/000001929_03_000249_2_De Aardbol Magazijn van hedendaagsche land en volkenkunde Met platen en kaarten [Deel 4 9 by P H W ]_1839.jpg&#39;),Path(&#39;data/cv_workshop_exercise_data/people/000194796_0_000133_1_Historical Collections relating to the history and antiquities of every town in Massachusetts with geographical descriptions [With illustrations ]_1839.jpg&#39;),Path(&#39;data/cv_workshop_exercise_data/people/000194796_0_000140_1_Historical Collections relating to the history and antiquities of every town in Massachusetts with geographical descriptions [With illustrations ]_1839.jpg&#39;),Path(&#39;data/cv_workshop_exercise_data/people/000001929_03_000058_1_De Aardbol Magazijn van hedendaagsche land en volkenkunde Met platen en kaarten [Deel 4 9 by P H W ]_1839.jpg&#39;),Path(&#39;data/cv_workshop_exercise_data/people/001099118_02_000168_1_The Victories of the British Armies with anecdotes illustrative of modern warfare By the author of Stories of Waterloo [i e William Hamilton Maxwell] etc [With plates ]_1839.jpg&#39;),Path(&#39;data/cv_workshop_exercise_data/people/000001929_08_000107_1_De Aardbol Magazijn van hedendaagsche land en volkenkunde Met platen en kaarten [Deel 4 9 by P H W ]_1839.jpg&#39;),Path(&#39;data/cv_workshop_exercise_data/people/000001929_06_000006_1_De Aardbol Magazijn van hedendaagsche land en volkenkunde Met platen en kaarten [Deel 4 9 by P H W ]_1839.jpg&#39;),Path(&#39;data/cv_workshop_exercise_data/people/000979699_0_000368_1_Indian Captivities being a collection of the most remarkable narratives of persons taken captive by the North American Indians To which are added notes historical biographical etc_1839.jpg&#39;),Path(&#39;data/cv_workshop_exercise_data/people/000001929_06_000007_1_De Aardbol Magazijn van hedendaagsche land en volkenkunde Met platen en kaarten [Deel 4 9 by P H W ]_1839.jpg&#39;),Path(&#39;data/cv_workshop_exercise_data/people/000001929_08_000106_1_De Aardbol Magazijn van hedendaagsche land en volkenkunde Met platen en kaarten [Deel 4 9 by P H W ]_1839.jpg&#39;)...] . PILImage.create(people[5]) . What happens if we predict one of these: . learn.predict(PILImage.create(people[5])) . (&#39;building&#39;, tensor(0), tensor([0.9916, 0.0084])) . It&#39;s predict that Torstenson is a building with a probability of 99% certainty! Let&#39;s look at some more . preds, _ = learn.get_preds(dl=learn.dls.test_dl(people)) . now we have a bunch of predictions let&#39;s get the max value. i.e. the probability for the label it predicted and see what the min, max and median is: . preds.max(dim=1)[0].min(), preds.max(dim=1)[0].max(), preds.max(dim=1)[0].median() . (tensor(0.5288), tensor(1.0000), tensor(0.9765)) . Although the min is fairly low, the median value is pretty confidently predicting a wrong label. Let&#39;s see how this differs if we instead use a &#39;label model&#39;. fastai expects labels to be inside a list, we can create a new column which puts our classes inside a list. . df[&#39;label&#39;] = df[&#39;class_label&#39;].apply(lambda x: [x]) . We&#39;ll now load in the data. The only difference here is that we specify a y_block, this forces fastai to choose the correct loss function. . dls_label = ImageDataLoaders.from_df(df,fn_col=&#39;fname&#39;, valid_pct=0.4, label_col=&#39;label&#39;, y_block=MultiCategoryBlock, item_tfms=Resize(128, ResizeMethod.Squish), bs=8, num_workers=0) dls_label.show_batch() . If we now create the learner, we&#39;ll see a different loss function . label_learn = cnn_learner(dls_label, resnet18, metrics=[F1ScoreMulti()]) label_learn.loss_func . FlattenedLoss of BCEWithLogitsLoss() . Again we&#39;ll fit for a while . label_learn.fit(5) . epoch train_loss valid_loss f1_score time . 0 | 0.979886 | 1.107939 | 0.520422 | 00:03 | . 1 | 0.742499 | 0.530855 | 0.749681 | 00:03 | . 2 | 0.540384 | 0.294314 | 0.858553 | 00:03 | . 3 | 0.428714 | 0.197953 | 0.874603 | 00:03 | . 4 | 0.358649 | 0.157847 | 0.973684 | 00:03 | . Now we&#39;ll grab some predictions again . preds, _ = label_learn.get_preds() preds . tensor([[9.8592e-01, 2.2629e-02], [5.0721e-01, 1.0558e-01], [9.9954e-01, 1.4539e-02], [2.6342e-01, 9.7471e-01], [9.9732e-01, 3.8691e-04], [1.0064e-02, 9.9507e-01], [1.5311e-02, 9.7020e-01], [2.2675e-03, 9.9944e-01], [9.7902e-01, 2.7719e-02], [6.0582e-01, 1.2015e-01], [7.7181e-02, 9.9448e-01], [9.8096e-01, 5.7364e-03], [8.2864e-01, 4.2955e-01], [9.0980e-01, 1.1982e-02], [9.6249e-01, 1.3159e-02], [2.3728e-01, 6.0858e-01], [9.9327e-01, 4.9904e-03], [9.1160e-04, 9.8218e-01], [9.7016e-01, 2.2057e-03], [9.8055e-01, 1.9247e-02], [8.3900e-01, 2.7438e-01], [4.3518e-01, 1.6118e-01], [6.8165e-01, 1.7120e-01], [7.7239e-01, 5.4064e-02], [9.9350e-01, 7.2269e-02], [6.3511e-01, 1.7830e-02], [1.3994e-01, 8.5564e-01], [2.6746e-02, 6.9240e-01]]) . Let&#39;s see what these add up to . preds.sum(dim=1) . tensor([1.0085, 0.6128, 1.0141, 1.2381, 0.9977, 1.0051, 0.9855, 1.0017, 1.0067, 0.7260, 1.0717, 0.9867, 1.2582, 0.9218, 0.9756, 0.8459, 0.9983, 0.9831, 0.9724, 0.9998, 1.1134, 0.5964, 0.8528, 0.8265, 1.0658, 0.6529, 0.9956, 0.7191]) . Not 1! Again this is because our labels are now independent of each other. We can see that if we now grab the max for each possible lab and take the min, max and median we get quite different results . preds.max(dim=1)[0].min(), preds.max(dim=1)[0].max(), preds.max(dim=1)[0].median() . (tensor(0.4352), tensor(0.9995), tensor(0.9702)) . Since the labels are now independent these probabilities have a much wider range. The lowest value is lower than would be possible when we use a classification model with two classes. This might be useful when we are trying to capture labels which are not tightly defined and therefore we might want our model to have more &#39;flexibility&#39; in the predictions it makes. Let&#39;s see what happens if we predict the same image of Torstenson we had earlier . label_learn.predict(PILImage.create(people[5])) . ((#1) [&#39;building&#39;], tensor([ True, False]), tensor([0.9992, 0.0055])) . Oh dear, this seems to have the same problem as before. However, we have the option to set a threshold for predictions. If we set a threshold and train again... . label_learn = cnn_learner(dls_label, resnet18, metrics=[F1ScoreMulti()],loss_func=BCEWithLogitsLossFlat(thresh=0.9)) . label_learn.fit(5) . epoch train_loss valid_loss f1_score time . 0 | 0.746691 | 0.450183 | 0.655556 | 00:03 | . 1 | 0.572374 | 0.352565 | 0.843939 | 00:03 | . 2 | 0.477375 | 0.328633 | 0.856250 | 00:03 | . 3 | 0.359104 | 0.320807 | 0.841642 | 00:03 | . 4 | 0.306263 | 0.327382 | 0.860795 | 00:03 | . If we now predict the same image . label_learn.predict(PILImage.create(people[5])) . ((#0) [], tensor([False, False]), tensor([0.8369, 0.4833])) . This time we don&#39;t get a prediction! The flexibility of being able to set a threshold is a very nice feature of using this type of loss function since it gives you some more options for deciding how confident you want a model to be. . Discussion . The aim of this blog post was to explore some of the implications of doing &#39;classification&#39; vs &#39;labeling&#39;. Although label models are often only considered in relation to models with multiple labels, they can also be applied to models with only one possible label per image. The key distinction between these two approaches is the loss functions. There are implications of choosing between these two loss functions. . Because of the Softmax component, a classification model will always have probabilities for each class which add to one. Beyond this thought the use of the exponent tends to push one class probability higher than the others. . In contrast the loss function for a labeling model pushes each individual labels probability between 0 and 1, but it doesn&#39;t require all of label probabilities to add to 1. . Labeling in a Digital Humanities/GLAM context . When you have clear labels which are distinct from each other, it is useful to have one label be &#39;pushed to the top&#39;. Often in a humanities or GLAM context labels may not be as clear cut. . This might be because the concepts which you are trying to capture in the labels have fuzzy borders, or because the source material contains some complexities. For example, working with ORC&#39;d text of varying quality. In these situations the fact that softmax will be likely to lead to one prediction being much stronger may not be desirable. . Although you can work with the raw probabilities predicted by the model to capture some potential ambiguity, because one class will tend to be pushed higher (because of the exponent in softmax) this doesn&#39;t fully address this issue. . A preference for one or another approach, will depend on the task at hand but even when you only have one single possible label per input, it might still be helpful to consider using a labeling model i.e. BCELoss instead of a classification model using CrossEntropyLoss. . There are of course other solutions to changing out the loss function you used to train the model. I&#39;m hoping to explore some of these soon ü§ì .",
            "url": "https://danielvanstrien.xyz/models/labels/loss%20functions/2020/10/12/labelling_vs_classification_models.html",
            "relUrl": "/models/labels/loss%20functions/2020/10/12/labelling_vs_classification_models.html",
            "date": " ‚Ä¢ Oct 12, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Virtual memory",
            "content": "Conda . Package installation . Use Mambda instead of conda to install packages. We&#39;ve done what we do at @QuantStack: making things run faster. Conda has been getting slower with @condaforge&#39;s growing package registry -- we&#39;re fighting it with raw C++ power in the #mamba package!Try now:conda install mamba -c conda-forge/label/mamba-alpha -c conda-forge pic.twitter.com/tnlVQKAbv4 . &mdash; Wolf Vollprecht (@wuoulf) March 25, 2019 . Pandas . import pandas as pd . Drop rows if frequency of a class id below n . sometimes it can be useful to drop rows in a dataset which appear to few times, in the most extreme cases datasets might have only one observation for a particular class. . rows = [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;2&#39;,&#39;1&#39;]; df = pd.DataFrame({&#39;a&#39;:rows, &#39;b&#39;: rows}) . df . a b . 0 1 | 1 | . 1 2 | 2 | . 2 3 | 3 | . 3 2 | 2 | . 4 1 | 1 | . df[df.groupby(&#39;a&#39;)[&#39;a&#39;].transform(&#39;count&#39;).ge(2)] . a b . 0 1 | 1 | . 1 2 | 2 | . 3 2 | 2 | . 4 1 | 1 | . fastai . Some things related to fastai (version 2) . Inference . Sources of information: . https://forums.fast.ai/t/doing-predictions-and-showing-results-with-v2-questions-best-practice-thread/62915/6 | . from fastai.vision.all import * . Train a learner so we can do some inference . path = untar_data(URLs.PETS) files = get_image_files(path/&quot;images&quot;) def label_func(f): return f[0].isupper() dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(32), num_workers=0) . dls.show_batch() . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.999297 | 0.718680 | 0.324763 | 01:26 | . epoch train_loss valid_loss error_rate time . 0 | 0.722174 | 0.548298 | 0.272666 | 01:41 | . Making predictions . preds = learn.get_preds() . Decoding predictions . To decode the output from get_preds. Can decode a label using the dls. Accessing the categorize.decode attribute to get a human readable value. . dls.categorize.decode(0) . &#39;False&#39; . If we have the predictions tensors i.e. the predictions for each class: . preds[0][0] . tensor([0.2110, 0.7890]) . numpy argmax can be used to get the index of the most likely predictions` . dls.categorize.decode(np.argmax(preds[0][0])) . &#39;True&#39; . Can also access the confidence for the maximum prediction directly; . max(preds[0][0]) . tensor(0.7890) . Test time augmentation . dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(32), batch_tfms=[*aug_transforms()],num_workers=0) learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fit(1) . epoch train_loss valid_loss error_rate time . 0 | 0.898633 | 0.700572 | 0.299729 | 01:11 | . doc(learn.tta) . Learner.tta[source] . Learner.tta(ds_idx=1, dl=None, n=4, item_tfms=None, batch_tfms=None, beta=0.25, use_max=False) . Return predictions on the ds_idx dataset or dl using Test Time Augmentation . Show in docs . preds, targs = learn.tta() . . error_rate(preds, targs).item() . 0.28890395164489746 . Dataloaders . Accessing input data . Accessing the input from the data loaders can be done through items. The L here is just to automagically limit the number of items displayed in the notebook . L(dls.items) . (#5912) [Path(&#39;/Users/dvanstrien/.fastai/data/oxford-iiit-pet/images/Bengal_76.jpg&#39;),Path(&#39;/Users/dvanstrien/.fastai/data/oxford-iiit-pet/images/shiba_inu_8.jpg&#39;),Path(&#39;/Users/dvanstrien/.fastai/data/oxford-iiit-pet/images/newfoundland_87.jpg&#39;),Path(&#39;/Users/dvanstrien/.fastai/data/oxford-iiit-pet/images/english_cocker_spaniel_11.jpg&#39;),Path(&#39;/Users/dvanstrien/.fastai/data/oxford-iiit-pet/images/pug_50.jpg&#39;),Path(&#39;/Users/dvanstrien/.fastai/data/oxford-iiit-pet/images/chihuahua_58.jpg&#39;),Path(&#39;/Users/dvanstrien/.fastai/data/oxford-iiit-pet/images/British_Shorthair_74.jpg&#39;),Path(&#39;/Users/dvanstrien/.fastai/data/oxford-iiit-pet/images/pomeranian_75.jpg&#39;),Path(&#39;/Users/dvanstrien/.fastai/data/oxford-iiit-pet/images/Russian_Blue_104.jpg&#39;),Path(&#39;/Users/dvanstrien/.fastai/data/oxford-iiit-pet/images/Bengal_77.jpg&#39;)...] . Indexing dataloader items . Items can be indexed in the usual way which can be useful to get back to orginal input based on an index . dls.items[0] . Path(&#39;/Users/dvanstrien/.fastai/data/oxford-iiit-pet/images/german_shorthaired_54.jpg&#39;) . Git . Filtering repositories . If you end up with a big repository which you want to split off into a new repo but maintain the history for the stuff in that folder. Use https://github.com/newren/git-filter-repo/ to filter the repo itself. To do this I pulled the old repo into a new folder to make sure I didn&#39;t destroy anything by mistake. You filter out a repo based on a folder and other potential filters. Once this repo has been filtered you can push it to a new repo. .",
            "url": "https://danielvanstrien.xyz/fastai/conda/pandas/2020/08/29/code_snippets.html",
            "relUrl": "/fastai/conda/pandas/2020/08/29/code_snippets.html",
            "date": " ‚Ä¢ Aug 29, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Hyperparameter Optimization for Transfer Learning",
            "content": "tl;dr . This post covers: . the motivations for &#39;pragmatic hyperparameters optimization&#39; | how to do this using Optuna (with an example applied to the fastai2 library) | . Optimizing hyperparameters? . Deep learning models have a range of Hyperparameters. These include the basic building blocks of a model like the number of layers used or the size of embedding layers, and the parameters for the training of models such as learning rate. Changing some of these parameters will improve the performance of a model. There is therefore a potential win from finding the right values for these parameters. . Auto ML vs pragmatic hyperparameters optimization . As a way of framing &#39;pragmatic search&#39;, it is useful to contrast it to Auto ML. If you haven&#39;t come across it before: . The term AutoML has traditionally been used to describe automated methods for model selection and/or hyperparameter optimization. - 1. . In particular what is termed Auto ML often includes a search across model and Hyperparameters but can also refer to &#39;Neural Architecture Search&#39; in which the objective is to piece together a new model type for a specific problem or dataset. An underlying assumption of some of this Auto ML approach is that each problem or dataset requires a unique model architecture. . In contrast a more &#39;pragmatic&#39; approach uses an existing model architectures which have been shown to work across a range of datasets and tasks, and utilise transfer learning and other &#39;tricks&#39; like cyclical learning rates and data augmentation. In a heritage context, it is likely that there are going to be bigger issues with imbalanced classes, noisy labels etc, and focusing on designing a custom architecture is probably going to lead to modest improvements in the performance of the model. . So what remains to be optimized? . In contrast to Auto ML which can involve looking at huge range of potential architectures and parameters we could instead limit our focus to smaller set of things which may have a large impact on the performance of your model. . As an example use case for hyperparameters optimization I&#39;ll use two datasets which contain transcripts of trials from the Old Bailey online and which are classified into various categories (theft, deception, etc). One of the datasets is drawn the decade 1830 the other one 1730. The approach taken to classifying these trials will be to follow the &quot;Universal Language Model Fine-tuning for Text Classification&quot; approach. 2. . I won&#39;t give an in depth summary of the approach here but idea is that: . A language model - in this case a LSTM based model - is trained on a Wikipedia text. This provides a &quot;general&quot; language model that learns to &quot;understand&quot; general features of a language, in this case English | this language model is then fine-tuned on a target dataset, in the orginal paper this is IMDB movie reviews. | one this language model has been fine-tuned on the target dataset this fine-tuned language model is used as input for a classifier | . The intuition here is that by utilising a pre-trained language model the Wikipedia part, and the fine-tuning part we get the benefits of a massive training set (Wikipedia) whilst also being able to &#39;focus&#39; the language model on a target corpus which will use language differently. This makes a lot of intuitive sense, but a question in this use case is how much to fine-tune the language model on our target datasets. A reasonable assumption might be that since language will be more different in 1730 compared to 1830 we may want to fine tune the language model trained on Wikipedia more on the 1730 dataset. . We could of course test through some trial and error experiments, but this is a question which may benefit from some more systematic searching for appropriate hyperparameters. Before we get into this example in more depth I&#39;ll discuss the library I&#39;m working with for doing this hyperparameter searching. . Optuna: A hyperparameter optimization framework . In this post I will be using Optuna &quot;an automatic hyperparameter optimization software framework, particularly designed for machine learning&quot;. 3. . There are some really nice features in Optuna which I&#39;ll cover in this post as I explore the question of language model fine-tuning, so hopefully even if you don&#39;t care about the specific use case it might still provide a useful overview of Optuna. . In this blog post my examples will use version two of the fastai library but there really isn&#39;t anything that won&#39;t translate to other frameworks. Optuna has integrations for a number of libraries (including version 1 of fastai) but for this blog I won&#39;t use this integration. . A simple optimization example . To show the approach used in Optuna I&#39;ll use a simple image classification example. In this case using a toy example of classifying people vs cats in images taken from 19th Century books. . Optuna has two main concepts to understand: study and trial. A study is the overarching process of optimization based on some objective function. A trial is a single test/execution of the objective function. We&#39;ll return to this in more detail. For now lets look at a simple example. . For our first example we&#39;ll just use Optuna to test whether to use a pre-trained model or not. If the option is True then the ResNet18 model we use will use weights from pre-training on ImageNet, if False the model will start with random weights. . Looking at the high level steps of using Optuna (I&#39;ll go into more detail later). We create an objective function: . !wget -q https://zenodo.org/record/3689444/files/humancats.zip?download=1 !unzip -q *humancats.zip* -d data/ . . def objective(trial): is_pretrained = trial.suggest_categorical(&#39;pre_trained&#39;, [True, False]) dls = ImageDataLoaders.from_folder(&#39;data/human_vs_cats/&#39;, valid_pct=0.4, item_tfms=Resize(64)) learn = cnn_learner(dls, resnet18, pretrained=is_pretrained, metrics=[accuracy]) learn.fit(1) acc = learn.recorder.values[-1][-1] return acc . Most of this will look familiar if you are have used fastai before. Once we have this we create a study: . study = optuna.create_study(direction=&#39;maximize&#39;) . and then optimize this study: . study.optimize(objective, n_trials=2) . epoch train_loss valid_loss accuracy time . 0 | 1.503035 | 0.710954 | 0.555556 | 00:06 | . [I 2020-06-04 16:58:49,862] Finished trial#0 with value: 0.5555555820465088 with parameters: {&#39;pre_trained&#39;: False}. Best is trial#0 with value: 0.5555555820465088. . epoch train_loss valid_loss accuracy time . 0 | 1.691165 | 1.218440 | 0.555556 | 00:05 | . [I 2020-06-04 16:58:56,272] Finished trial#1 with value: 0.5555555820465088 with parameters: {&#39;pre_trained&#39;: False}. Best is trial#0 with value: 0.5555555820465088. . Once we&#39;ve run some trials we can inspect the study object for the best value we&#39;re optimizing for. In this case this is the accuracy but it will be whatever is returned by our function. We can also see the parameters which led to this value. . study.best_value, study.best_params . (0.5555555820465088, {&#39;pre_trained&#39;: False}) . This toy example wasn&#39;t particularly useful (it just confirmed we probably want to use a pre-trained model) but going through the steps provides an overview of the main things required by Optuna. Starting with defining a function objective . def objective(trial): . this is the function we want to optimize. We could call it something else but following the convention in the Optuna docs the function we&#39;ll call it objective. This function takes &#39;trial&#39; as an argument. . is_pretrained = trial.suggest_categorical(&#39;pre_trained&#39;, [True, False]) . here we use trial to &quot;suggest&quot; a categorical in this case one of two options (whether pre trained is set to true or false). We do this using trial.suggest_categorical and pass it the potential options (in this case True or False). . trial.suggest_blah defines the paramater &quot;search space&quot; for Optuna. We&#39;ll look at all of the options for this later on. The final step in defining our objective function i.e. the thing we want to optimize: . return acc . This return value is objective value that Optuna will optimize. Because this is just the return value of a function there is a lot of flexibility in what this can be. In this example it is accuracy but it could be training or validation loss, or another training metrics. Later on we&#39;ll look at this in more detail. . Now let&#39;s look at the study part: . study = optuna.create_study(direction=&#39;maximize&#39;) . This is the most simple way of creating a study. This creates a study object, again, we&#39;ll look at more options as we go along. The one option we pass here is the direction. This refers to to whether Optuna should try to increase the return value of our optimization function or decrease it. This depends on what you a tracking i.e. you&#39;d want to minimize error or validation loss but increase accuracy or F1 score. . Looking at the overview provided in the Optuna docs we have three main building blocks: . Trial: A single call of the objective function . | Study: An optimization session, which is a set of trials . | Parameter: A variable whose value is to be optimized . | . Parameter search space . Borrowing once more from the docs: . The difficulty of optimization increases roughly exponentially with regard to the number of parameters. That is, the number of necessary trials increases exponentially when you increase the number of parameters, so it is recommended to not add unimportant parameters . This is a crucial point. Particularly if we want to use optimization in a pragmatic way. When we have existing knowledge or evidence about what works well for a particular problem, we should use that rather than asking Optuna to find this out for us. There are some extra tricks to make our search for the best parameters more efficient which will be explored below but for now let&#39;s get back to the example use case. . Fine-tuning a language model . df_1830 = pd.read_csv(&#39;https://gist.githubusercontent.com/davanstrien/4bc85d8a4127a2791732280ffaa43293/raw/cd1a3cc53674b64c8f130edbcb34e835afa665fb/1830trial.csv&#39;) df_1730 = pd.read_csv(&#39;https://gist.githubusercontent.com/davanstrien/4bc85d8a4127a2791732280ffaa43293/raw/cd1a3cc53674b64c8f130edbcb34e835afa665fb/1730trial.csv&#39;) . . For the sake of brevity I won&#39;t cover the steps to generate this dataset the instructions for doing so for the 1830s trials can be found here (and can be easily adapted for the 1730s trial). . Unnamed: 0 Unnamed: 0.1 0 file broad narrow text . 0 14463.0 | t18361128-57a | theft-housebreaking | t18361128-57a.txt | theft | housebreaking | n n n n n57. n n n n nJOHN BYE n the younger and n n n n nFREDERICK BYE n were indicted for n n feloniously breaking and entering the dwelling-house of n n n nJohn Bye, on the n21st of November, at nSt. Giles-in-the-Fields, and stealing therein 12 apples, value 9d.; 1 box, value 1d.; 24 pence, and 1 twopenny-piece; the goods and monies of n n n nMary Byrne. n n n n n n nMARY BYRNE n. I sell fruit; I live in Titchbourne-court, Holborn. On the 21st of November I went out at one o&#39;clock, and locked my door?I left 2s. worth of penny-pieces in my drawer, and two dozen large apples?I came... | . 1 19021.0 | t18380917-2214 | theft-pocketpicking | t18380917-2214.txt | theft | pocketpicking | n n n n2214. n n n n nMARY SMITH n was indicted n n for stealing, on the n16th of September, 1 purse, value 2d.; 3 half-crowns, and twopence; the goods and monies of n n n nGeorge Sainsbury, from his person. n n n n n n nGEORGE SAINSBURY n. Between twelve and one o&#39;clock, on the 16th of September, I went to sleep in the fields, at Barnsbury-park, Islington, I had three half-crowns, and twopence, in my pocket?I was awoke, and missed my money?I went to the prisoner, and charged her with it?she said she had not got it?I followed her, and saw her drop ray purse down, it had two penny piece... | . We load the data using fastai2 TextDataLoaders . def load_lm_data(df): data_lm = TextDataLoaders.from_df( df.sample(frac=0.5), text_col=&quot;text&quot;, is_lm=True, bs=128 ) return data_lm # Classification data def load_class_data(df, data_lm): data_class = TextDataLoaders.from_df( df.sample(frac=0.5), text_col=&quot;text&quot;, label_col=&quot;broad&quot;, valid_pct=0.3, bs=128, text_vocab=data_lm.vocab, ) return data_class . . data_lm = load_lm_data(df_1830) data_class = load_class_data(df_1830, data_lm) . Create the language model learner and classifier learner: . def create_lm(): return language_model_learner(data_lm, AWD_LSTM, pretrained=True).to_fp16() def create_class_learn(): return text_classifier_learner( data_class, AWD_LSTM, metrics=[accuracy, F1Score(average=&quot;weighted&quot;)] ).to_fp16() . . Optuna trial suggest . In the example above trial.suggest_categorical was used to define the potential parameter. Optuna has five kinds of parameters which can be optimized. These all work through the trial.suggest method. . Categorical . This can be used for models, optimizers, and for True/False flags. . optimizer = trial.suggest_categorical(&#39;optimizer&#39;, [&#39;MomentumSGD&#39;, &#39;Adam&#39;]) . Integer . n_epochs = trial.suggest_int(&#39;num_epochs&#39;, 1, 3) . Uniform . max_zoom = trial.suggest_uniform(&#39;max_zoom&#39;, 0.0, 1.0) . Loguniform . learning_rate = trial.suggest_loguniform(&#39;learning_rate&#39;, 1e-4, 1e-2) . Discrete-uniform . drop_path_rate = trial.suggest_discrete_uniform(&#39;drop_path_rate&#39;, 0.0, 1.0) . The string value provides a key for the parameters which is used to access these parameters later, it&#39;s therefore important to give them a sensible name. . Limiting parameters? . Adding additional trial.suggest to your optimization function increases the search space for Optuna to optimize over so you should avoid adding additional parameters if they are not necessary. . The other way in which the search space can be constrained is to limit the range of the search i.e. for learning rate . learning_rate = trial.suggest_loguniform(&#39;learning_rate&#39;, 1e-4, 1e-2) . is preferable over . learning_rate = trial.suggest_loguniform(&#39;learning_rate&#39;, 1e-10, 1e-1) . if it&#39;s not likely the optimal learning rate will sit outside of this range. . How many parameters you include will also depend on the type of model you are trying to train. In the use case of fine-tuning a language model we will want to limit the options more since language models are generally quite slow to train. If, on the other hand, we were trying to improve an image classification model which only takes minutes to train then searching through a larger parameter space would become more feasible. . Objective function for fine-tuning a language model . The objective function below has two stages; train a language model, use the encoder from this language model for a classifier. . The parameters we&#39;re trying to optimize in this case are: . learning rate for the frozen language model | number of epochs to train only the final layers of the language model | learning rate for the unfrozen language model | number of epochs for training the whole language model | . We use lm_learn.no_bar() as a context manager to reduce the amount of logging. . def objective(trial): lm_learn = create_lm() lr_frozen = trial.suggest_loguniform(&quot;learning_rate_frozen&quot;, 1e-4, 1e-1) head_epochs = trial.suggest_int(&quot;head_epochs&quot;, 1, 5) with lm_learn.no_bar(): lm_learn.fit_one_cycle(head_epochs, lr_max=lr_frozen) # Unfrozen Language model lr_unfreeze = trial.suggest_loguniform(&quot;learning_rate_unfrozen&quot;, 1e-7, 1e-1) body_epochs = trial.suggest_int(&quot;lm_body_epochs&quot;, 1, 5) lm_learn.unfreeze() with lm_learn.no_bar(): lm_learn.fit_one_cycle(body_epochs, lr_unfreeze) lm_learn.save_encoder(&quot;finetuned&quot;) # Classification cl_learn = create_class_learn() cl_learn.load_encoder(&quot;finetuned&quot;) cl_learn.fit_one_cycle(3) f1 = cl_learn.recorder.values[-1][-1] return f1 . We can give our study a name and also store it in a database. This allows for resuming previous trials later and accessing the history of previous trials. There are various options for database backends outlined in the documentation. . Creating the study . study_name = &quot;tunelm1830&quot; study = optuna.create_study( study_name=study_name, direction=&quot;maximize&quot;, storage=f&quot;sqlite:///{out_path}/optuma/example.db&quot;, ) . [I 2020-06-05 15:09:05,470] A new study created with name: tunelm1830 . Optimize . Now we&#39;ll run 3 trials and use show_progress_bar=True to give an ETA on when the trials will finish. . study.optimize(objective, n_trials=3, show_progress_bar=True) . /usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:61: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future. . (#4) [0,5.382655620574951,4.875850200653076,&#39;00:24&#39;] (#4) [1,5.292355537414551,4.737764835357666,&#39;00:24&#39;] (#4) [2,5.183778285980225,4.647550106048584,&#39;00:24&#39;] (#4) [3,5.11093282699585,4.608272552490234,&#39;00:24&#39;] (#4) [4,5.072442054748535,4.601930618286133,&#39;00:24&#39;] (#4) [0,4.7495622634887695,4.241390228271484,&#39;00:27&#39;] . epoch train_loss valid_loss accuracy f1_score time . 0 | 2.326032 | 2.070412 | 0.020000 | 0.017034 | 00:10 | . 1 | 2.302230 | 2.136864 | 0.023333 | 0.003590 | 00:10 | . 2 | 2.269061 | 2.180663 | 0.016667 | 0.004408 | 00:10 | . [I 2020-06-05 15:12:20,128] Finished trial#0 with value: 0.00440805109922757 with parameters: {&#39;learning_rate_frozen&#39;: 0.00014124685078723662, &#39;head_epochs&#39;: 5, &#39;learning_rate_unfrozen&#39;: 0.00010276862511970148, &#39;lm_body_epochs&#39;: 1}. Best is trial#0 with value: 0.00440805109922757. (#4) [0,4.713407516479492,3.7350399494171143,&#39;00:24&#39;] (#4) [1,3.998744249343872,3.3055806159973145,&#39;00:24&#39;] (#4) [2,3.6486754417419434,3.192685842514038,&#39;00:24&#39;] (#4) [3,3.4996860027313232,3.1756556034088135,&#39;00:24&#39;] (#4) [0,3.4227023124694824,3.163315534591675,&#39;00:27&#39;] (#4) [1,3.3954737186431885,3.140226364135742,&#39;00:27&#39;] (#4) [2,3.3778774738311768,3.125929117202759,&#39;00:27&#39;] (#4) [3,3.357388973236084,3.119621753692627,&#39;00:27&#39;] (#4) [4,3.3542206287384033,3.1186859607696533,&#39;00:27&#39;] . epoch train_loss valid_loss accuracy f1_score time . 0 | 2.368984 | 2.121307 | 0.013333 | 0.000759 | 00:11 | . 1 | 2.335033 | 2.022853 | 0.250000 | 0.368652 | 00:10 | . 2 | 2.296630 | 1.948786 | 0.313333 | 0.452365 | 00:10 | . [I 2020-06-05 15:16:49,562] Finished trial#1 with value: 0.45236502121696065 with parameters: {&#39;learning_rate_frozen&#39;: 0.0060643425219262335, &#39;head_epochs&#39;: 4, &#39;learning_rate_unfrozen&#39;: 2.734844423029637e-05, &#39;lm_body_epochs&#39;: 5}. Best is trial#1 with value: 0.45236502121696065. (#4) [0,5.3748459815979,4.851675987243652,&#39;00:24&#39;] (#4) [1,5.247058868408203,4.672318935394287,&#39;00:24&#39;] (#4) [2,5.111597061157227,4.559732437133789,&#39;00:24&#39;] (#4) [3,5.026832103729248,4.512131690979004,&#39;00:24&#39;] (#4) [4,4.982809066772461,4.5044732093811035,&#39;00:24&#39;] (#4) [0,4.915407657623291,4.423311233520508,&#39;00:27&#39;] (#4) [1,4.857243061065674,4.394893646240234,&#39;00:27&#39;] . epoch train_loss valid_loss accuracy f1_score time . 0 | 2.368439 | 2.036706 | 0.240000 | 0.360355 | 00:10 | . 1 | 2.359790 | 2.093103 | 0.033333 | 0.045878 | 00:09 | . 2 | 2.331945 | 2.140194 | 0.016667 | 0.013589 | 00:10 | . [I 2020-06-05 15:20:20,119] Finished trial#2 with value: 0.013588651008106425 with parameters: {&#39;learning_rate_frozen&#39;: 0.0001971120155925954, &#39;head_epochs&#39;: 5, &#39;learning_rate_unfrozen&#39;: 1.0649951798153689e-05, &#39;lm_body_epochs&#39;: 2}. Best is trial#1 with value: 0.45236502121696065. . Results . You can see how trials are peforming in the logs with the last part of the log reporting the best trial so far. We can now access the best value and best_params. . study.best_value, study.best_params . (0.45236502121696065, {&#39;head_epochs&#39;: 4, &#39;learning_rate_frozen&#39;: 0.0060643425219262335, &#39;learning_rate_unfrozen&#39;: 2.734844423029637e-05, &#39;lm_body_epochs&#39;: 5}) . Where to start the search? . As I mentioned at the start I think it&#39;s worth trying to think pragmatically about how to use hyper-parameter optimizations. I already mentioned limiting the number of parameters and limiting the potential options in these parameters. However we can also intervene more directly in how Optuna runs a trial. . Suggesting a learning rate . One of the yummiest features in fastai which has also made it into other deep-learning libraries is the learning rate finer lr_find(). As a reminder: . the LR Finder trains the model with exp onentially growing learning rates from start_lr to end_lr for num_it and stops in case of divergence (unless stop_div=False) then plots the losses vs the learning rates with a log scale. . Since the Learning rate finder often gives a good learning rate we should see if we can use this as a starting point for our trials. . Enqueue trial . Using enqueue_trial you can queue up trials with specied paramters. This can be for all of the parameters or just a subset. We can use lr_find to suggest a learning rate for the language model and then que a trial with this learning rate. . lm_learn = create_lm() lm_learn.unfreeze() . lr_min,lr_steep = lm_learn.lr_find(suggestions=True) . lr_min, lr_steep . (0.014454397559165954, 0.033113110810518265) . study.enqueue_trial({&#39;learning_rate_unfrozen&#39;: lr_steep}) study.optimize(objective, n_trials=1) . /usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:61: ExperimentalWarning: enqueue_trial is experimental (supported from v1.2.0). The interface can change in the future. . (#4) [0,5.322241306304932,4.736147403717041,&#39;00:24&#39;] (#4) [1,5.095097541809082,4.474568843841553,&#39;00:24&#39;] (#4) [2,4.91882848739624,4.365659713745117,&#39;00:24&#39;] (#4) [3,4.820737838745117,4.348053455352783,&#39;00:24&#39;] (#4) [0,3.5270116329193115,3.0885186195373535,&#39;00:27&#39;] (#4) [1,3.1028788089752197,2.8053553104400635,&#39;00:27&#39;] (#4) [2,2.7882776260375977,2.611638069152832,&#39;00:27&#39;] (#4) [3,2.49800705909729,2.539992094039917,&#39;00:27&#39;] . epoch train_loss valid_loss accuracy f1_score time . 0 | 2.325723 | 2.102552 | 0.010000 | 0.006709 | 00:10 | . 1 | 2.293266 | 2.006258 | 0.216667 | 0.332841 | 00:10 | . 2 | 2.258634 | 1.928858 | 0.566667 | 0.686662 | 00:10 | . [I 2020-06-05 15:28:58,707] Finished trial#3 with value: 0.6866621960133127 with parameters: {&#39;head_epochs&#39;: 4, &#39;learning_rate_frozen&#39;: 0.0003841551576945897, &#39;learning_rate_unfrozen&#39;: 0.033113110810518265, &#39;lm_body_epochs&#39;: 4}. Best is trial#3 with value: 0.6866621960133127. . Using the learning rate from the LR_finder gives us our best trial so far. This is likely to be because learning rate is a particularly important hyper-parameter. The suggested learning rate from lr_find may not always be the best but using either the suggested one or picking one based on the plot as a starting point for the trial may help Optuna to start from sensible starting point while still giving the freedom for optuna to diverge away from this in later trials if helps the objective function. . Pruning trials . The next feature of Optuna which helps make parameter searching more efficient is pruning. Pruning is a process for stopping bad trials early. . For example if we have the following three trials: . Trial 1 - epoch 1: 87% accuracy | Trial 2 - epoch 1: 85% accuracy | Trial 3 - epoch 1: 60% accuracy | . probably it&#39;s not worth continuing with trial 3. Pruning trials helps focus computational resources on trials which are likely to improve on previous trials. The likely here is important. It is possible that some trials may be pruned early which actually would have done better in the end. Optuna offers a number of different pruning algorithms, I won&#39;t cover these here but the documentation gives a good overview and includes links to the papers which propose the implemented pruning algorithms. . How to do pruning in Optuna? . Optuna has intergrations with various machine learning libraries. These intergrations can help with the pruning but setting up pruning manually is also pretty straight forward to do. . The two things we need to do is report the value and the stage in the training porcess: . trial.report(metric, step) . then we call: . if trial.should_prune(): raise optuna.exceptions.TrialPruned() . Depending on your objective function this will be put in different places. In the example of fine-tuning the language model, because we&#39;re trying to optimize the classification part it, it means the pruning step can only be called quite late in the traing loop. Ideally it would be called earlier but we still save a little bit of time on unpromising trials. . The new objective function with pruning: . def objective(trial): lm_learn = create_lm() lr_frozen = trial.suggest_loguniform(&quot;learning_rate_frozen&quot;, 1e-4, 1e-1) head_epochs = trial.suggest_int(&quot;head_epochs&quot;, 1, 5) with lm_learn.no_bar(): lm_learn.fit_one_cycle(head_epochs, lr_max=lr_frozen) # Unfrozen Language model lr_unfreeze = trial.suggest_loguniform(&quot;learning_rate_unfrozen&quot;, 1e-7, 1e-1) body_epochs = trial.suggest_int(&quot;lm_body_epochs&quot;, 1, 5) lm_learn.unfreeze() with lm_learn.no_bar(): lm_learn.fit_one_cycle(body_epochs, lr_unfreeze) lm_learn.save_encoder(&quot;finetuned&quot;) # Classification cl_learn = create_class_learn() cl_learn.load_encoder(&quot;finetuned&quot;) for step in range(3): cl_learn.fit(1) # Pruning intermediate_f1 = cl_learn.recorder.values[-1][ -1 ] # get f1 score for current step trial.report(intermediate_f1, step) # report f1 if trial.should_prune(): # let optuna decide whether to prune raise optuna.exceptions.TrialPruned() f1 = cl_learn.recorder.values[-1][-1] return f1 . We can load the same study as before using the python load_if_exists flag. . study_name = &quot;tunelm1830&quot; study = optuna.create_study( study_name=study_name, direction=&quot;maximize&quot;, storage=f&quot;sqlite:///{out_path}/optuma/example.db&quot;, load_if_exists=True, pruner=optuna.pruners.SuccessiveHalvingPruner(), ) . [I 2020-06-06 14:30:47,724] Using an existing study with name &#39;tunelm1830&#39; instead of creating a new one. . We can now run some more trials. Instead of specifying the number of trials we can also specify how long optuma should search for. . study.enqueue_trial({&#39;learning_rate_unfrozen&#39;: lr_steep}) study.optimize(objective, timeout=60*60*0.5) . and get the best trial: . study.best_trial . FrozenTrial(number=13, value=0.8657462002717475, datetime_start=datetime.datetime(2020, 6, 5, 15, 59, 26, 230967), datetime_complete=datetime.datetime(2020, 6, 5, 16, 3, 26, 392390), params={&#39;head_epochs&#39;: 4, &#39;learning_rate_frozen&#39;: 0.0012866609022148768, &#39;learning_rate_unfrozen&#39;: 1.3302852136460371e-06, &#39;lm_body_epochs&#39;: 4}, distributions={&#39;head_epochs&#39;: IntUniformDistribution(high=5, low=1, step=1), &#39;learning_rate_frozen&#39;: LogUniformDistribution(high=0.1, low=0.0001), &#39;learning_rate_unfrozen&#39;: LogUniformDistribution(high=0.1, low=1e-07), &#39;lm_body_epochs&#39;: IntUniformDistribution(high=5, low=1, step=1)}, user_attrs={}, system_attrs={&#39;completed_rung_0&#39;: 0.8156506309537317}, intermediate_values={0: 0.251088767516275, 1: 0.8156506309537317, 2: 0.8657462002717475}, trial_id=14, state=TrialState.COMPLETE) . and best value and pararms: . study.best_value, study.best_params . (0.8657462002717475, {&#39;head_epochs&#39;: 4, &#39;learning_rate_frozen&#39;: 0.0012866609022148768, &#39;learning_rate_unfrozen&#39;: 1.3302852136460371e-06, &#39;lm_body_epochs&#39;: 4}) . Paramters for the 1730s trials data . We can do the same process with the 1730s trials, starting with a suggested learning rate. . data_lm = load_lm_data(df_1730) data_class = load_class_data(df_1730, data_lm) lm_learn = create_lm() lm_learn.unfreeze() lr_min,lr_steep = lm_learn.lr_find(suggestions=True) . . def objective(trial): lm_learn = create_lm() lr_frozen = trial.suggest_loguniform(&quot;learning_rate_frozen&quot;, 1e-4, 1e-1) head_epochs = trial.suggest_int(&quot;head_epochs&quot;, 1, 5) with lm_learn.no_bar(): lm_learn.fit_one_cycle(head_epochs, lr_max=lr_frozen) # Unfrozen Language model lr_unfreeze = trial.suggest_loguniform(&quot;learning_rate_unfrozen&quot;, 1e-7, 1e-1) body_epochs = trial.suggest_int(&quot;lm_body_epochs&quot;, 1, 5) lm_learn.unfreeze() with lm_learn.no_bar(): lm_learn.fit_one_cycle(body_epochs, lr_unfreeze) lm_learn.save_encoder(&quot;finetuned&quot;) # Classification cl_learn = create_class_learn() cl_learn.load_encoder(&quot;finetuned&quot;) for step in range(3): cl_learn.fit(1) intermediate_f1 = cl_learn.recorder.values[-1][-1] trial.report(intermediate_f1, step) if trial.should_prune(): raise optuna.exceptions.TrialPruned() f1 = cl_learn.recorder.values[-1][-1] return f1 . . study_name = &quot;tunelm1730&quot; study = optuna.create_study( study_name=study_name, direction=&quot;maximize&quot;, storage=f&quot;sqlite:///{out_path}/optuma/example.db&quot;, load_if_exists=True, pruner=optuna.pruners.SuccessiveHalvingPruner(), ) . . [I 2020-06-08 15:06:54,474] Using an existing study with name &#39;tunelm1730&#39; instead of creating a new one. . study.enqueue_trial({&#39;learning_rate_unfrozen&#39;: lr_steep}) study.optimize(objective, timeout=60*60*0.5) . Trials can be accssed as part of the study object. Running trials for 30 mins with early pruning results in 20 trials . len(study.trials) . 20 . We can also see which was the best trial. . study.best_trial.number . 2 . The number of trials run depends mainly on how long your model takes to train, the size of the paramter search space and your patience. If trials are failing to improve better scores for a long time it&#39;s probably better to actively think about how to improve your approach to the problem (better data, more data, chaning model design etc.) rather than hoping hyperaparmet tuning will fix the problem. . Comparing language model parameters . Previous trials can be loaded using load_study . study1830 = optuna.load_study(&#39;tunelm1830&#39;, storage=f&#39;sqlite:///{out_path}/optuma/example.db&#39;) study1730 = optuna.load_study(&#39;tunelm1730&#39;, storage=f&#39;sqlite:///{out_path}/optuma/example.db&#39;) . First comparing the best f1 values for both datasets: . print(f&#39;Best 1830 value was: {study1830.best_value:.3}&#39;) print(f&#39;Best 1730 value was: {study1730.best_value:.3}&#39;) . Best 1830 value was: 0.866 Best 1730 value was: 0.781 . The paramters used to get the best value: . 1830 parameters . {&#39;head_epochs&#39;: 4, &#39;learning_rate_frozen&#39;: 0.0012866609022148768, &#39;learning_rate_unfrozen&#39;: 1.3302852136460371e-06, &#39;lm_body_epochs&#39;: 4} . 1730 parameters . {&#39;head_epochs&#39;: 3, &#39;learning_rate_frozen&#39;: 0.002145480897071231, &#39;learning_rate_unfrozen&#39;: 9.889236991663078e-06, &#39;lm_body_epochs&#39;: 1} . Specific parameters can also be accessed . study1830.best_params[&#39;learning_rate_unfrozen&#39;], study1730.best_params[&#39;learning_rate_unfrozen&#39;] . (1.3302852136460371e-06, 9.889236991663078e-06) . Visualizations . Optuna has a variety of visulizations, I will only briefly show a few of these here. . plot_intermediate_values shows the intermediate values. This can be useful for getting a sense of how trials progress and also help give a sense of whether some trials are being pruned prematurely . optuna.visualization.plot_intermediate_values(study1830) . . . plot_parallel_coordinate plots parameters choices in relation to values. It can be hard to read these plots but they can also be helpful for giving a sense of which choices for parameters work best. . optuna.visualization.plot_parallel_coordinate(study1830) . . . Parameter importance . Optuna has experimental support for getting parameter importance. . optuna.importance.get_param_importances(study1730) . /usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:61: ExperimentalWarning: get_param_importances is experimental (supported from v1.3.0). The interface can change in the future. /usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:83: ExperimentalWarning: MeanDecreaseImpurityImportanceEvaluator is experimental (supported from v1.5.0). The interface can change in the future. . OrderedDict([(&#39;learning_rate_frozen&#39;, 0.43423246892923717), (&#39;learning_rate_unfrozen&#39;, 0.2904735896601219), (&#39;head_epochs&#39;, 0.2433021650269149), (&#39;lm_body_epochs&#39;, 0.031991776383726155)]) . optuna.importance.get_param_importances(study1830) . /usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:61: ExperimentalWarning: get_param_importances is experimental (supported from v1.3.0). The interface can change in the future. /usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:83: ExperimentalWarning: MeanDecreaseImpurityImportanceEvaluator is experimental (supported from v1.5.0). The interface can change in the future. . OrderedDict([(&#39;learning_rate_unfrozen&#39;, 0.35548906967729954), (&#39;learning_rate_frozen&#39;, 0.33998779901100146), (&#39;head_epochs&#39;, 0.21196438930810765), (&#39;lm_body_epochs&#39;, 0.09255874200359132)]) . These are broadly similar although learning rate frozen/unfrozen are in different places for the 1730 and 1830 trials. . Multi objective . Optuna has experimental support for multi-objective optimization. This might be useful if you don&#39;t want to optimize for only one metrics. . An alternative to using this approach is to report other things you care about during the trial but don&#39;t directly want to optimize for. As an example, you might mostly care about the accuracy of a model but also care a bit about how long it takes to do inference. . One approach is to use a multi-objective trial. An alternative is to instead log inference time as part of the trial and continue to optimize for other metrics. You can then later on balance the accuracy of different trials with the inference time. It may turn out later that a slightly slower inference time can be dealt with by scaling vertically. Not prematurely optimizing for multi-objectives can therefore give you more flexibility. To show this in practice I&#39;ll use an image classification dataset. . The data . The data is images of maps and other things from historic newspapers. The aim is to classify whether the image is a map or something else. . dls = ImageDataLoaders.from_folder( &quot;data/1905_maps/&quot;, valid_pct=0.3, item_tfms=Resize(256) ) dls.show_batch() . learn.unfreeze() lr_min,unfrozen_lr_steep = learn.lr_find(suggestions=True) . Excessive model parameter search . Since the time to train the model is more reasonable we can add a more parameters to the search space. In practice this is pretty overkill but is useful as an example of working with the outputs of trials with many parameters. . def objective(trial): apply_tfms = trial.suggest_categorical(&quot;apply_tfms&quot;, [True, False]) if apply_tfms: aug_tfms = aug_transforms( mult=trial.suggest_uniform(&quot;mult&quot;, 0.0, 1.0), do_flip=trial.suggest_categorical(&quot;do_flip&quot;, [True, False]), flip_vert=trial.suggest_categorical(&quot;flip_vert&quot;, [True, False]), max_rotate=trial.suggest_uniform(&quot;max_rotate&quot;, 0, 180), max_zoom=trial.suggest_uniform(&quot;max_zoom&quot;, 0, 3.0), max_lighting=trial.suggest_uniform(&quot;max_lighting&quot;, 0.0, 1.0), ) else: aug_tfms = None dls = ImageDataLoaders.from_folder( &quot;data/1905_maps/&quot;, valid_pct=0.3, item_tfms=Resize(256), aug_transforms=aug_tfms ) model = trial.suggest_categorical( &quot;model&quot;, [&quot;resnet18&quot;, &quot;resnet50&quot;, &quot;xresnet50&quot;, &quot;squeezenet1_0&quot;, &quot;densenet121&quot;] ) learn = cnn_learner( dls, arch=eval(model), pretrained=True, metrics=[F1Score(average=&quot;weighted&quot;)] ).to_fp16() epochs = trial.suggest_int(&quot;epochs&quot;, 1, 10) for step in range(epochs): with learn.no_bar(): learn.fit_one_cycle( 1, base_lr=trial.suggest_loguniform(&quot;learning_rate&quot;, 1e-5, 1e-1) ) unfrozen_epochs = trial.suggest_int(&quot;unfrozen_epochs&quot;, 1, 10) unfrozen_lr = trial.suggest_loguniform(&quot;unfrozen_learning_rate&quot;, 1e-10, 1e-1) learn.unfreeze() for step in range(unfrozen_epochs): with learn.no_bar(): learn.fit_one_cycle(1, lr_max=unfrozen_lr) int_f1 = learn.recorder.values[-1][-1] trial.report(int_f1, step) if trial.should_prune(): raise optuna.exceptions.TrialPruned() t0 = time.time() learn.validate() t1 = time.time() execute_time = t1 - t0 trial.set_user_attr(&quot;execute_time&quot;, execute_time) f1 = learn.recorder.values[-1][-1] return f1 . Create the study . study_name = &quot;mapsmegastudyXL&quot; # Unique identifier of the study. study = optuna.create_study( direction=&quot;maximize&quot;, load_if_exists=True, study_name=study_name, storage=f&quot;sqlite:///{out_path}/optuma/blog.db&quot;, pruner=optuna.pruners.SuccessiveHalvingPruner(min_resource=2), ) . [I 2020-06-07 15:03:24,138] Using an existing study with name &#39;mapsmegastudyXL&#39; instead of creating a new one. . Queue up with some parameters . study.enqueue_trial( { &quot;pre_trained&quot;: True, &quot;apply_tfms&quot;: True, &quot;epochs&quot;: 5, &quot;learning_rate&quot;: lr_steep, &quot;model&quot;: &quot;resnet50&quot;, &quot;unfrozen_learning_rate&quot;: unfrozen_lr_steep, } ) study.optimize(objective, n_trials=1, show_progress_bar=True) . /usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:61: ExperimentalWarning: enqueue_trial is experimental (supported from v1.2.0). The interface can change in the future. /usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:61: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future. . (#5) [0,1.162647008895874,1.0643662214279175,0.38594077225581136,&#39;00:04&#39;] (#5) [0,1.1730060577392578,0.8583190441131592,0.45458674870439575,&#39;00:02&#39;] (#5) [0,0.7940309047698975,0.40110471844673157,0.8101934029975151,&#39;00:02&#39;] (#5) [0,0.3774714767932892,0.3251221776008606,0.8738329238329239,&#39;00:02&#39;] (#5) [0,0.20592834055423737,0.304998517036438,0.8914149443561209,&#39;00:02&#39;] (#5) [0,0.14400754868984222,0.3399428725242615,0.9003332765709003,&#39;00:03&#39;] (#5) [0,0.11649172753095627,0.3571062982082367,0.8729641116526362,&#39;00:03&#39;] . [I 2020-06-07 15:03:57,405] Finished trial#0 with value: 0.8729641116526362 with parameters: {&#39;apply_tfms&#39;: True, &#39;do_flip&#39;: False, &#39;epochs&#39;: 5, &#39;flip_vert&#39;: True, &#39;learning_rate&#39;: 0.00015848931798245758, &#39;max_lighting&#39;: 0.5155363265412508, &#39;max_rotate&#39;: 93.50185801538605, &#39;max_zoom&#39;: 2.5014402368129147, &#39;model&#39;: &#39;resnet50&#39;, &#39;mult&#39;: 0.7973732804273224, &#39;unfrozen_epochs&#39;: 2, &#39;unfrozen_learning_rate&#39;: 1.4454397387453355e-05}. Best is trial#0 with value: 0.8729641116526362. . queue up with some less sensible defaults . study.enqueue_trial( {&quot;pre_trained&quot;: False, &quot;apply_tfms&quot;: False, &quot;epochs&quot;: 1, &quot;unfrozen_epochs&quot;: 1} ) study.optimize(objective, n_trials=1, show_progress_bar=True) . /usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:61: ExperimentalWarning: enqueue_trial is experimental (supported from v1.2.0). The interface can change in the future. /usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:61: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future. . (#5) [0,1.1455873250961304,1.7333940267562866,0.3123010228273386,&#39;00:01&#39;] (#5) [0,1.0485259294509888,1.4432364702224731,0.4545249081834448,&#39;00:01&#39;] . [I 2020-06-07 15:04:18,823] Finished trial#1 with value: 0.4545249081834448 with parameters: {&#39;apply_tfms&#39;: False, &#39;epochs&#39;: 1, &#39;learning_rate&#39;: 1.4039901997074766e-05, &#39;model&#39;: &#39;resnet18&#39;, &#39;unfrozen_epochs&#39;: 1, &#39;unfrozen_learning_rate&#39;: 4.041607859100835e-07}. Best is trial#0 with value: 0.8729641116526362. . Now optimize for 500 trials . study.optimize(objective, n_trials=500,show_progress_bar=True) . study = optuna.load_study(&#39;mapsmegastudyXL&#39;, storage=f&#39;sqlite:///{out_path}/optuma/blog.db&#39;) . The best finishing values and parameters: . study.best_value, study.best_params . (0.963975663975664, {&#39;apply_tfms&#39;: True, &#39;do_flip&#39;: True, &#39;epochs&#39;: 10, &#39;flip_vert&#39;: False, &#39;learning_rate&#39;: 0.0785689562916925, &#39;max_lighting&#39;: 0.5064203068969654, &#39;max_rotate&#39;: 168.972217754609, &#39;max_zoom&#39;: 1.6141746329756919, &#39;model&#39;: &#39;densenet121&#39;, &#39;mult&#39;: 0.6087267126078458, &#39;unfrozen_epochs&#39;: 4, &#39;unfrozen_learning_rate&#39;: 7.6080876225791396e-06}) . Visualization . Taking a look at parallel_coordinate in this case gives some sense of which options work best. . optuna.visualization.plot_parallel_coordinate(study) . . . Importance . optuna.importance.get_param_importances(study) . /usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:61: ExperimentalWarning: get_param_importances is experimental (supported from v1.3.0). The interface can change in the future. /usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:83: ExperimentalWarning: MeanDecreaseImpurityImportanceEvaluator is experimental (supported from v1.5.0). The interface can change in the future. . OrderedDict([(&#39;unfrozen_learning_rate&#39;, 0.6945560978629778), (&#39;epochs&#39;, 0.13207296757949719), (&#39;model&#39;, 0.07996254760084977), (&#39;unfrozen_epochs&#39;, 0.04455237119259635), (&#39;learning_rate&#39;, 0.04014544684326522), (&#39;apply_tfms&#39;, 0.008710568920813712)]) . Learning rate is by far the most important learning rate, again this suggests that using learning rate finder makes a lot of sense as a starting point. . Working with Optuna trial data . There are now ~500 trials which are stored in the study. Each of these trials contains the parameters used, metadata about the trial, the value of the thing being optimized, and importantly for this example the user attribute which stores the validation time. Optuna makes it very easy to export this information to a dataframe. . df = study.trials_dataframe() df.head(3) . number value datetime_start datetime_complete duration params_apply_tfms params_do_flip params_epochs params_flip_vert params_learning_rate params_max_lighting params_max_rotate params_max_zoom params_model params_mult params_unfrozen_epochs params_unfrozen_learning_rate user_attrs_execute_time system_attrs_completed_rung_0 system_attrs_completed_rung_1 system_attrs_fixed_params state . 0 0 | 0.872964 | 2020-06-07 15:03:29.911841 | 2020-06-07 15:03:57.151460 | 00:00:27.239619 | True | False | 5.0 | True | 0.000158 | 0.515536 | 93.501858 | 2.50144 | resnet50 | 0.797373 | 2.0 | 1.445440e-05 | 0.82319 | NaN | NaN | {&#39;pre_trained&#39;: True, &#39;apply_tfms&#39;: True, &#39;epochs&#39;: 5, &#39;learning_rate&#39;: 0.00015848931798245758, &#39;model&#39;: &#39;resnet50&#39;, &#39;unfrozen_learning_rate&#39;: 1.4454397387453355e-05} | COMPLETE | . 1 1 | 0.454525 | 2020-06-07 15:04:11.520248 | 2020-06-07 15:04:18.419082 | 00:00:06.898834 | False | NaN | 1.0 | NaN | 0.000014 | NaN | NaN | NaN | resnet18 | NaN | 1.0 | 4.041608e-07 | 0.67698 | NaN | NaN | {&#39;pre_trained&#39;: False, &#39;apply_tfms&#39;: False, &#39;epochs&#39;: 1, &#39;unfrozen_epochs&#39;: 1} | COMPLETE | . 2 2 | NaN | 2020-06-07 15:04:32.047588 | NaT | NaT | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | RUNNING | . We can now easily work with the trial data using pandas. Lets start by getting the best two values . df.sort_values([&#39;value&#39;], ascending=False).head(2) . Unnamed: 0 number value datetime_start datetime_complete duration params_apply_tfms params_do_flip params_epochs params_flip_vert ... params_max_zoom params_model params_mult params_unfrozen_epochs params_unfrozen_learning_rate user_attrs_execute_time system_attrs_completed_rung_0 system_attrs_completed_rung_1 system_attrs_fixed_params state . 177 177 | 177 | 0.963976 | 2020-06-07 16:48:36.232551 | 2020-06-07 16:49:21.393454 | 0 days 00:00:45.160903000 | True | True | 10.0 | False | ... | 1.614175 | densenet121 | 0.608727 | 4.0 | 7.608088e-06 | 0.880459 | 0.954955 | NaN | NaN | COMPLETE | . 302 302 | 302 | 0.955064 | 2020-06-07 18:11:00.667449 | 2020-06-07 18:11:45.658241 | 0 days 00:00:44.990792000 | True | True | 10.0 | False | ... | 0.921689 | densenet121 | 0.115708 | 4.0 | 6.210737e-10 | 0.878865 | 0.945946 | NaN | NaN | COMPLETE | . 2 rows √ó 23 columns . We can see how often transforms were applied in the trials . df[&#39;params_apply_tfms&#39;].value_counts() . True 360 False 142 Name: params_apply_tfms, dtype: int64 . Viewing the number of trials for each model which had a value over 90 . df[&#39;params_model&#39;][df[&#39;value&#39;] &gt;= 0.90].value_counts() . densenet121 181 resnet50 9 squeezenet1_0 2 Name: params_model, dtype: int64 . Filtering a bit more aggressively (value above 94) . df94 = df[df[&#39;value&#39;] &gt;= 0.94] . len(df94) . 13 . How often were transforms applied for these trials . df94[&#39;params_apply_tfms&#39;].value_counts() . True 11 False 2 Name: params_apply_tfms, dtype: int64 . The number of unfrozen epochs . df94[&#39;params_unfrozen_epochs&#39;].value_counts() . 4.0 6 2.0 3 3.0 2 6.0 1 5.0 1 Name: params_unfrozen_epochs, dtype: int64 . Getting back to the validation time we can get the max, min and mean values . df[&#39;user_attrs_execute_time&#39;].max(), df[&#39;user_attrs_execute_time&#39;].min(), df[&#39;user_attrs_execute_time&#39;].mean() . (0.9760787487030028, 0.6313643455505371, 0.8461264789613903) . If we did care about reducing the execution time we could use these values to find the trial with the shortest execution time: . df94[&#39;user_attrs_execute_time&#39;].sort_values() . 96 0.837618 426 0.848863 394 0.849243 395 0.851704 438 0.852672 500 0.863168 344 0.875520 432 0.877422 302 0.878865 177 0.880459 473 0.884703 372 0.906770 294 0.907221 Name: user_attrs_execute_time, dtype: float64 . If we were happy with slightly lower performance we could pick the study with the shortest execution time which is still achieves a f1 above 94% . df94.loc[96] . number 96 value 0.945755 datetime_start 2020-06-07 15:57:20.382634 datetime_complete 2020-06-07 15:57:54.848296 duration 0 days 00:00:34.465662 params_apply_tfms False params_do_flip NaN params_epochs 9 params_flip_vert NaN params_learning_rate 8.47479e-05 params_max_lighting NaN params_max_rotate NaN params_max_zoom NaN params_model densenet121 params_mult NaN params_unfrozen_epochs 2 params_unfrozen_learning_rate 4.31178e-07 user_attrs_execute_time 0.837618 system_attrs_completed_rung_0 NaN system_attrs_completed_rung_1 NaN system_attrs_fixed_params NaN state COMPLETE Name: 96, dtype: object . This is a slightly artificial example but hopefully shows the possibility of logging user attributes which can then be accessed easily later without prematurely optimizing for something which may not be important. . Further reading . Hopefully this post has been a helpful overview of Optuna with a somewhat realistic use case. I would recommend reading the Optuna docs which covers things in much more detail. . References . 1. Auto ml [auto-ml, fastai blog(https://www.fast.ai/2018/07/16/auto-ml2/#auto-ml‚Ü© . 2. introducting ulmfit nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html‚Ü© . 3. Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta,and Masanori Koyama. 2019. Optuna: A Next-generation Hyperparameter Optimization Framework. In KDD.‚Ü© .",
            "url": "https://danielvanstrien.xyz/hyperparameter%20optimisation/optimisation/optuna/fastai2/transfer%20learning/2020/07/01/optuna.html",
            "relUrl": "/hyperparameter%20optimisation/optimisation/optuna/fastai2/transfer%20learning/2020/07/01/optuna.html",
            "date": " ‚Ä¢ Jul 1, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Multi-model metadata generation",
            "content": "Learning from multiple input types . Deep learning models usually take one type of input (image, text etc.) to predict output labels (category, entities etc). This usually makes sense if the data you are using to make predictions contains a lot of information. i.e. a chunk of text from a movie review or an image. . Recently I have been playing around with a Website Classification Dataset from the UK web archive. The dataset is derived from a manually curated web archive which contains a primary and secondary category for each web page. The UK web archive has made a dataset available based on this archive which contains the manually classified subject categories alongside the page URL and the page title. . As part of playing around with this dataset I was keen to see if a multi-input model would work well. In this case exploring a model that takes both text and tabular data as input. A preview of the data: . Primary Category Secondary Category Title URL . 0 Arts &amp; Humanities | Architecture | 68 Dean Street | http://www.sixty8.com/ | . 1 Arts &amp; Humanities | Architecture | Abandoned Communities | http://www.abandonedcommunities.co.uk/ | . 2 Arts &amp; Humanities | Architecture | Alexander Thomson Society | http://www.greekthomson.com/ | . 3 Arts &amp; Humanities | Architecture | Arab British Centre, The | http://www.arabbritishcentre.org.uk/ | . 4 Arts &amp; Humanities | Architecture | Architectural Association School of Architecture | http://www.aaschool.ac.uk/ | . Based on this data the UK web archive are interested: . &quot;in understanding whether high-level metadata like this can be used to train an appropriate automatic classification system so that we might use this manually generated dataset to partially automate the categorisation of our larger archives.&quot; . This is going to be fairly tricky but offers a nice excuse to try to use models with multiple inputs to predict our categories. . Looking at the data . Taking a closer look at the data: . Unique primary categories . len(df[&#39;Primary Category&#39;].unique()) . 24 . Unique secondary categories . len(df[&#39;Secondary Category&#39;].unique()) . 104 . Predicting a 104 different labels is going to be pretty difficult so I&#39;ve only used &#39;Primary Category&#39; as the the y target. What is the distribution of these categories like? . Arts &amp; Humanities 5299 Government, Law &amp; Politics 4832 Business, Economy &amp; Industry 2988 Society &amp; Culture 2984 Science &amp; Technology 2420 Medicine &amp; Health 2164 Education &amp; Research 2118 Company Web Sites 843 Digital Society 737 Sports and Recreation 710 Religion 417 Travel &amp; Tourism 374 Social Problems and Welfare 270 Politics, Political Theory and Political Systems 123 Crime, Criminology, Police and Prisons 101 Literature 87 Law and Legal System 81 Computer Science, Information Technology and Web Technology 54 Libraries, Archives and Museums 52 Environment 38 History 34 Publishing, Printing and Bookselling 26 Popular Science 23 Life Sciences 23 Name: Primary Category, dtype: int64 . üò¨ We also have a fairly skewed datasets. I could drop some of rows which don&#39;t occur often but since the main objective here is to see if we can use a multi-input model we&#39;ll leave the data as it is for now. . Multi-input model . The rest of the notebook will describe some experiments with using fastai to create a model which takes tabular and text data as an input. The aim here wasn&#39;t for me to create the best model but get my head around how to combine models. I heavily relied on some existing notebooks, kaggle writeup and forum posts on the fastai forums. . Tabular model . In the dataset above we start of with two columns of data which can be used as inputs for the model. The title is fairly obviously something which we can treat like other text inputs. The URL is a little less obvious. It could be treated as a text input but an alternative is to treat a URL as parts which each contain some information which could be useful for our model. . http://www.specialschool.org/ http://www.bbc.co.uk/news/health-12668398 http://www.monarchit.co.uk/ . Each part of the URL could be split into smaller parts . [&#39;http://www&#39;, &#39;darwincountry&#39;, &#39;org/&#39;] . Whether a url has &#39;.org&#39; or &#39;.uk&#39; or &#39;.com&#39; could be meaningful for predicting our categories (it might also not be meaningful). It also offers us a way of taking the URLs and composing it into a format which looks more tabular. . scheme url1 url3 url4 url5 . 20011 http | www | org | NaN | NaN | . 15825 http | www | com | NaN | NaN | . 6068 http | www | co | uk | NaN | . 16507 http | www | co | uk | NaN | . 9723 http | www | co | uk | NaN | . So far I&#39;ve only done this very crudely. I suspect tidying up this part of the data will help improve things. At this point though we have something which is a little more tabular looking we can pass to fastai.tabular learner. Now we have some &#39;categories&#39; rather than unique urls. . print(len(df.url3.unique())) print(len(df.url4.unique())) . 279 56 . How does this tabular model do? . Once some preprocessing of the url has been done we train a model using the tabular learner. I didn&#39;t do much to try to optimize this model. Tracking best f2 score we end up with: . Better model found at epoch 36 with f_beta value: 0.17531482875347137 and an accuracy of 0.334121 . How well does a text model do? . Next I tried training using the title field in a NLP model. I tried a few things here. . SentencePiece tokenization . By default fastai uses SpaCy to do tokenization with a few additional special tokens added by fastai. I wanted to see if using sentencePiece would work better for processing title fields. SentencePiece allows for various sub-word tokeinzation. This can be useful for agglutinative languages but could also be useful when you have a lot of out of vocabulary words in your corpus. I wanted to see if this also was useful for processing titles since these may contain domain specific terms. I only tried using SentencePiece with &#39;unigram&#39; tokenization. The best score I got for this was: . Better model found at epoch 1 with f_beta value: 0.21195338666439056. . Default SpaCy tokenization . I compared the above to using the default fastai tokenizer which uses SpaCy. In this case the default approach worked better. This is probably because we didn&#39;t have a large pre-trained model using the SentencePiece tokenization to use as a starting point. The best score I got for this model was: . Better model found at epoch 27 with f_beta value: 0.33327043056488037. . Using the URL as text input . I wanted to do a quick comparison to the tabular model and use the URL as a text input instead. In this case I used SentencePiece with byte-pair-encoding (BPE). The best score in this case was: . Better model found at epoch 3 with f_beta value: 0.2568161189556122. . This might end up being a better approach compared to the tabular approach described above. . Combining inputs . Neither of these models is doing super well but my main question was whether combining the two would improve things at all. There are different approaches to combining these models. I followed existing examples and removed some layers from the text and tabular models which are then combined in a concat model. I won&#39;t cover all the steps here but all the notebooks can be found in this GitHub repo. . One of the things we need to do to create a model with multiple input is create a new Pytorch dataset which combines our text and tabular x inputs with our target. This is pretty straightforward: . class ConcatDataset(Dataset): def __init__(self, x1, x2, y): self.x1,self.x2,self.y = x1,x2,y def __len__(self): return len(self.y) def __getitem__(self, i): return (self.x1[i], self.x2[i]), self.y[i] . . One of the other pieces was creating a ConcatModel . class ConcatModel(nn.Module): def __init__(self, model_tab, model_nlp, layers, drops): super().__init__() self.model_tab = model_tab self.model_nlp = model_nlp lst_layers = [] activs = [nn.ReLU(inplace=True),] * (len(layers)-2) + [None] for n_in,n_out,p,actn in zip(layers[:-1], layers[1:], drops, activs): lst_layers += bn_drop_lin(n_in, n_out, p=p, actn=actn) # https://docs.fast.ai/layers.html#bn_drop_lin self.layers = nn.Sequential(*lst_layers) def forward(self, *x): x_tab = self.model_tab(*x[0]) x_nlp = self.model_nlp(x[1])[0] x = torch.cat([x_tab, x_nlp], dim=1) return self.layers(x) . . lst_layer is dependent on the layers from the tabular and nlp models. This layer is manually defined at the moment, so if changes are made to the number of layers in the tab model this needs to be manually changed. . bn_drop_lin is a fastai helper function that returns a a sequence of batch normalization, dropout and a linear layer which is the final layer of the model. . How does this combined model do? &#129335;&#8205;&#9794;&#65039; . The best result I got wasf_beta value: 0.39341238141059875 with an accuracy of 0.595348. A summary of the scores for each models: . Model F2 score . SentencePiece text | 0.211 | . Spacy text | 0.333 | . Tabular | 0.175 | . Concat | 0.393 | . This provides some improvement on the tabular or nlp models on their own. I found the combined model was fairly tricky to train and suspect that there could be some improvements in how the model is set up that might improve it&#39;s performance. I am keen to try a similar approach with a dataset where there is more abundant information available to train with. . tl;dr . It wasn&#39;t possible to get a very good f2 score on this website classification dataset. As the UK web archive say: . We expect that a appropriate classifier might require more information about each site in order to produce reliable results, and are looking at augmenting this dataset with further information in the future. Options include:For each site, make the titles of every page on that site available. For each site, extract a set of keywords that summarise the site, via the full-text index. . I suspect that having a either of these additional components would help improve the performance of the classifier. .",
            "url": "https://danielvanstrien.xyz/metadata/multi-model/2020/05/03/multi-model.html",
            "relUrl": "/metadata/multi-model/2020/05/03/multi-model.html",
            "date": " ‚Ä¢ May 3, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi, I‚Äôm Daniel. I‚Äôm a librarian interested in using computational methods to do research with library and archive collections. I‚Äôm particularly excited by the possibilities of using deep-learning both as part of the ‚Äúday-to-day‚Äù processes within a library setting and for enabling new kinds of research. . I currently work at the British Library as a Digital Curator for the Living with Machines project. .",
          "url": "https://danielvanstrien.xyz/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://danielvanstrien.xyz/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}