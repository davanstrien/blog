{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-model metadata generation\n",
    "> combining text and tabular models to generate web archive metadata\n",
    "\n",
    "- toc: true \n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [metadata, multi-model]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning from multiple input types  \n",
    " \n",
    "Deep learning models usually take one type of input (image, text etc.) to predict output labels (category, entities etc). This usually makes sense if the data you are using to make predictions contains a lot of information. i.e. a chunk of text from a movie review or an image. \n",
    "\n",
    "Recently I have been playing around with a Website Classification Dataset from the UK web archive. The dataset is derived from a manually curated web archive which contains a primary and secondary category for each web page. The UK web archive has made a [dataset](https://data.webarchive.org.uk/opendata/ukwa.ds.1/classification/) available based on this archive which contains the manually classified subject categories alongside the page URL and the page title. \n",
    "\n",
    "As part of playing around with this dataset I was keen to see if a multi-input model would work well. In this case exploring a model that takes both text and tabular data as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Primary Category</th>\n",
       "      <th>Secondary Category</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Arts &amp; Humanities</td>\n",
       "      <td>Architecture</td>\n",
       "      <td>68 Dean Street</td>\n",
       "      <td>http://www.sixty8.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Arts &amp; Humanities</td>\n",
       "      <td>Architecture</td>\n",
       "      <td>Abandoned Communities</td>\n",
       "      <td>http://www.abandonedcommunities.co.uk/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Arts &amp; Humanities</td>\n",
       "      <td>Architecture</td>\n",
       "      <td>Alexander Thomson Society</td>\n",
       "      <td>http://www.greekthomson.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Arts &amp; Humanities</td>\n",
       "      <td>Architecture</td>\n",
       "      <td>Arab British Centre, The</td>\n",
       "      <td>http://www.arabbritishcentre.org.uk/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Arts &amp; Humanities</td>\n",
       "      <td>Architecture</td>\n",
       "      <td>Architectural Association School of Architecture</td>\n",
       "      <td>http://www.aaschool.ac.uk/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Primary Category Secondary Category  \\\n",
       "0           0  Arts & Humanities       Architecture   \n",
       "1           1  Arts & Humanities       Architecture   \n",
       "2           2  Arts & Humanities       Architecture   \n",
       "3           3  Arts & Humanities       Architecture   \n",
       "4           4  Arts & Humanities       Architecture   \n",
       "\n",
       "                                              Title  \\\n",
       "0                                    68 Dean Street   \n",
       "1                             Abandoned Communities   \n",
       "2                         Alexander Thomson Society   \n",
       "3                          Arab British Centre, The   \n",
       "4  Architectural Association School of Architecture   \n",
       "\n",
       "                                      URL  \n",
       "0                  http://www.sixty8.com/  \n",
       "1  http://www.abandonedcommunities.co.uk/  \n",
       "2            http://www.greekthomson.com/  \n",
       "3   http://www.arabbritishcentre.org.uk/   \n",
       "4              http://www.aaschool.ac.uk/  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "import pandas as pd\n",
    "tsv ='https://gist.githubusercontent.com/davanstrien/5e22b725046eddc2f1ee06b108f27e48/raw/71426e6b92c7fa98140a95728a5ea55171b948cd/classification.tsv'\n",
    "df = pd.read_csv(tsv, error_bad_lines=False, index_col=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this data the UK web archive are interested: \n",
    ">\"in understanding whether high-level metadata like this can be used to train an appropriate automatic classification system so that we might use this manually generated dataset to partially automate the categorisation of our larger archives.\"\n",
    "\n",
    "This is going to be fairly tricky but offers an excuse to try to use models with multiple inputs to predict our categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the data\n",
    "Taking a closer look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input \n",
    "tsv = 'https://gist.githubusercontent.com/davanstrien/5e22b725046eddc2f1ee06b108f27e48/raw/71426e6b92c7fa98140a95728a5ea55171b948cd/classification.tsv'\n",
    "df = pd.read_csv(tsv, error_bad_lines=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Primary Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Secondary Category'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting a 104 different labels is going to be pretty difficult so I've only used 'Primary Category' as the the ```y``` target. What is the distribution of these categories like? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arts & Humanities                                              5299\n",
       "Government, Law & Politics                                     4832\n",
       "Business, Economy & Industry                                   2988\n",
       "Society & Culture                                              2984\n",
       "Science & Technology                                           2420\n",
       "Medicine & Health                                              2164\n",
       "Education & Research                                           2118\n",
       "Company Web Sites                                               843\n",
       "Digital Society                                                 737\n",
       "Sports and Recreation                                           710\n",
       "Religion                                                        417\n",
       "Travel & Tourism                                                374\n",
       "Social Problems and Welfare                                     270\n",
       "Politics, Political Theory and Political Systems                123\n",
       "Crime, Criminology, Police and Prisons                          101\n",
       "Literature                                                       87\n",
       "Law and Legal System                                             81\n",
       "Computer Science, Information Technology and Web Technology      54\n",
       "Libraries, Archives and Museums                                  52\n",
       "Environment                                                      38\n",
       "History                                                          34\n",
       "Publishing, Printing and Bookselling                             26\n",
       "Popular Science                                                  23\n",
       "Life Sciences                                                    23\n",
       "Name: Primary Category, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "df['Primary Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "😬 We also have a fairly skewed datasets. I could drop some of rows which don't occur often but since the main objective here is to see if we can use a multi-input model we'll leave the data as it is for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-input model \n",
    "\n",
    "The rest of the notebook will describe some experiments with using [fastai](https://docs.fast.ai/) to create a model which takes tabular and text data as an input. The aim here wasn't for me to create the best model but get my head around how to combine models. I heavily relied on some existing [notebooks](https://nbviewer.jupyter.org/gist/joshfp/b62b76eae95e6863cb511997b5a63118/5.full-deep-learning.ipynb), kaggle [writeup](https://www.kaggle.com/c/petfinder-adoption-prediction/discussion/89491) and forum posts on the [fastai forums](forums.fast.ai/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular model \n",
    "In the dataset above we start of with two columns of data which can be used as inputs for the model. The title is fairly obviously something which we can treat like other text inputs. The URL is a little less obvious. It could be treated as a text input but an alternative is to treat a URL as parts which each contain some information which could be useful for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.specialschool.org/\n",
      "http://www.bbc.co.uk/news/health-12668398\n",
      "http://www.monarchit.co.uk/\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "print(df.URL.sample(10).to_list()[3])\n",
    "print(df.URL.sample(10).to_list()[4])\n",
    "print(df.URL.sample(10).to_list()[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each part of the URL could be split into smaller parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://www', 'darwincountry', 'org/']\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "print(df.URL.sample(10).to_list()[3].split('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether a url has '.org' or '.uk' or '.com' could be meaningful for predicting our categories (it might also not be meaningful). It also offers us a way of taking the URLs and composing it into a format which looks more tabular. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scheme</th>\n",
       "      <th>url1</th>\n",
       "      <th>url3</th>\n",
       "      <th>url4</th>\n",
       "      <th>url5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20011</th>\n",
       "      <td>http</td>\n",
       "      <td>www</td>\n",
       "      <td>org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15825</th>\n",
       "      <td>http</td>\n",
       "      <td>www</td>\n",
       "      <td>com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>http</td>\n",
       "      <td>www</td>\n",
       "      <td>co</td>\n",
       "      <td>uk</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16507</th>\n",
       "      <td>http</td>\n",
       "      <td>www</td>\n",
       "      <td>co</td>\n",
       "      <td>uk</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9723</th>\n",
       "      <td>http</td>\n",
       "      <td>www</td>\n",
       "      <td>co</td>\n",
       "      <td>uk</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scheme url1 url3 url4 url5\n",
       "20011   http  www  org  NaN  NaN\n",
       "15825   http  www  com  NaN  NaN\n",
       "6068    http  www   co   uk  NaN\n",
       "16507   http  www   co   uk  NaN\n",
       "9723    http  www   co   uk  NaN"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "csv ='https://gist.githubusercontent.com/davanstrien/5e22b725046eddc2f1ee06b108f27e48/raw/4c2a27772bf4d959bf3e58cfa8de9e0b9be69ca7/03_classification_valid_train.csv'\n",
    "df = pd.read_csv(csv, index_col=0)\n",
    "df[['scheme','url1','url3','url4','url5']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far I've only done this very crudely. I suspect tidying up this part of the data will help improve things. At this point though we have something which is a little more tabular looking we can pass to ```fastai.tabular``` learner. Now we have some 'categories' rather than unique urls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print(len(df.url3.unique()))\n",
    "print(len(df.url4.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does this tabular model do? \n",
    "\n",
    "Once some preprocessing of the url has been done we train a model using the tabular learner. I didn't do much to try to optimize this model. Tracking best ```f2``` score we end up with:\n",
    "\n",
    "```Better model found at epoch 36 with f_beta value: 0.17531482875347137``` and an accuracy of ```0.334121```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  How well does a text model do?\n",
    "Next I tried training using the title field in a NLP model. I tried a few things here. \n",
    "\n",
    "### SentencePiece tokenization\n",
    "\n",
    "By default fastai uses SpaCy to do tokenization with a few additional special tokens added by fastai. I wanted to see if using [sentencepiece](https://github.com/google/sentencepiece) would work better for processing title fields. SentencePiece allows for various sub-word tokeinzation. This can be useful for agglutinative languages but could also be useful when you have a lot of out of vocabulary words in your corpus. I wanted to see if this also was useful for processing titles since these may contain domain specific terms. I only tried using SentencePiece with 'unigram' tokenization. The best score I got for this was:\n",
    "\n",
    "```Better model found at epoch 1 with f_beta value: 0.21195338666439056.``` \n",
    "### Default SpaCy tokenization\n",
    "\n",
    "I compared the above to using the default fastai tokenizer which uses SpaCy. In this case the default approach worked better. This is probably because we didn't have a large pre-trained model using the SentencePiece tokenization to use as a starting point. The best score I got for this model was:\n",
    "\n",
    "```Better model found at epoch 27 with f_beta value: 0.33327043056488037.```\n",
    "\n",
    "### Using the URL as text input \n",
    "\n",
    "I wanted to do a quick comparison to the tabular model and use the URL as a text input instead. In this case I used SentencePiece with byte-pair-encoding (BPE). The best score in this case was:\n",
    "\n",
    "```Better model found at epoch 3 with f_beta value: 0.2568161189556122.```\n",
    "\n",
    "This might end up being a better approach compared to the tabular approach described above. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining inputs \n",
    "\n",
    "Neither of these models is doing super well but my main question was whether combining the two would improve things at all. There are different approaches to combining these models. I followed existing examples and removed some layers from the text and tabular models which are then combined in a concat model. I won't cover all the steps here but all the notebooks can be found in this [GitHub repo](https://github.com/davanstrien/Website-Classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.tabular import *\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from fastai import *\n",
    "from fastai.tabular import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.text import *\n",
    "from fastai.metrics import accuracy, MultiLabelFbeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the things we need to do to create a model with multiple input is create a new Pytorch dataset which combines our text and tabular ```x``` inputs with our target. This is pretty straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse_show\n",
    "class ConcatDataset(Dataset):\n",
    "    def __init__(self, x1, x2, y): \n",
    "        self.x1,self.x2,self.y = x1,x2,y\n",
    "    def __len__(self): \n",
    "        return len(self.y)\n",
    "    def __getitem__(self, i): \n",
    "        return (self.x1[i], self.x2[i]), self.y[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the other pieces was creating a ```ConcatModel```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse_show\n",
    "class ConcatModel(nn.Module):\n",
    "    def __init__(self, model_tab, model_nlp, layers, drops): \n",
    "        super().__init__()\n",
    "        self.model_tab = model_tab\n",
    "        self.model_nlp = model_nlp\n",
    "        lst_layers = []\n",
    "        activs = [nn.ReLU(inplace=True),] * (len(layers)-2) + [None]\n",
    "        for n_in,n_out,p,actn in zip(layers[:-1], layers[1:], drops, activs): \n",
    "            lst_layers += bn_drop_lin(n_in, n_out, p=p, actn=actn) # https://docs.fast.ai/layers.html#bn_drop_lin\n",
    "        self.layers = nn.Sequential(*lst_layers)\n",
    "\n",
    "    def forward(self, *x):\n",
    "        x_tab = self.model_tab(*x[0])\n",
    "        x_nlp = self.model_nlp(x[1])[0]\n",
    "        x = torch.cat([x_tab, x_nlp], dim=1)\n",
    "        return self.layers(x)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```lst_layer``` is dependent on the layers from the tabular and nlp models. This layer is manually defined at the moment, so if changes are made to the number of layers in the tab model this needs to be manually changed.  \n",
    "\n",
    "```bn_drop_lin``` is a fastai helper function that returns a a sequence of batch normalization, dropout and a linear layer which is the final layer of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does this combined model do? 🤷‍♂️\n",
    "\n",
    "The best result I got was``` f_beta value: 0.39341238141059875``` with an accuracy of ```0.595348```. A summary of the scores for each models:\n",
    "\n",
    "\n",
    "| Model | F2 score | \n",
    "|-------|--------|\n",
    "|SentencePiece text | 0.211  |\n",
    "| Spacy text | 0.333|\n",
    "| Tabular | 0.175 | \n",
    "|Concat| **0.393** |\n",
    "\n",
    "\n",
    "This provides some improvement on the tabular or nlp models on their own. I found the combined model was fairly tricky to train and suspect that there could be some improvements in how the model is set up that might improve it's performance. I am keen to try a similar approach with a dataset where there is more abundant information available to train with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tl;dr \n",
    "\n",
    "It wasn't possible to get a very good f2 score on this website classification dataset. As the UK web archive say:\n",
    "\n",
    "\n",
    "> We expect that a appropriate classifier might require more information about each site in order to produce reliable results, and are looking at augmenting this dataset with further information in the future. Options include:\n",
    "\n",
    "    For each site, make the titles of every page on that site available.\n",
    "    For each site, extract a set of keywords that summarise the site, via the full-text index.\n",
    "\n",
    "I suspect that having a either of these additional components would help improve the performance of the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
